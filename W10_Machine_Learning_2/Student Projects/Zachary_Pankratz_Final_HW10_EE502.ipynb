{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "71WE5smYL0K3"
   },
   "source": [
    "# Problem Text: Hallucinating the Constitution\n",
    "\n",
    "Consider the constitution of the United States:\n",
    "\n",
    "> https://www.usconstitution.net/const.txt .\n",
    "\n",
    "This document contains upper- and lower-case letters, numbers, and basic punctuation. \n",
    "\n",
    "**One letter prediction:**\n",
    "\n",
    "1. Find the set of all characters used in the document. Call the number of characters $n$. \n",
    "2. Create an $n \\times n$ matrix whose $i,j$ entry is the probability that the next character is $j$ given that the current character is $i$. Estimate this probability by looking at all occurrences of character $i$ in the document and the number of times character $j$ immediately follows it. \n",
    "3. Simulate this system as a Markov chain that starts with an arbitrary capital letter and continues until it gets to a space. Produce $100$ random \"words\" this way. How many of them are actual words? Use a [Scrabble dictionary](https://scrabble.hasbro.com/en-us/tools#dictionary) if you are not certain whether a given sequence is a word. \n",
    "\n",
    "**Two letter prediction:**\n",
    "\n",
    "1. Create an $n \\times n \\times n$ tensor whose $i,j,k$ entry is the probability that the next character is $k$ given that the current character is $j$ and the previous character is $i$. Use the document to empirically find these probabilities. \n",
    "2. Use this model to construct random words. \n",
    "\n",
    "**Sentence prediction:**\n",
    "\n",
    "Do a one word prediction, but use all the unique *words* in the document. Hallucinate sentences. Consider a punctuation mark as a word. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KusQ-lZ1RGiE"
   },
   "source": [
    "#Mathematical Descriptions\n",
    "\n",
    "For the rest of this document, I will intersperse mathematical descriptions for each part of each solution between the blocks of code, as well as justification the specific code used. The mathematical descriptions will be limited, as most of the math I used was in the area of probability and matrices/tensors, the rest is regular coding. \n",
    "\n",
    "In this first section, I import the necessary tools to run the code. I import from the urllib library which allows me to read in a text file from a url. The numpy library contains mathematical data structures and functions, the re library allows me to parse through strings using \"regular expressions\", and the collections library allows me to create a type of dictionary that parses through a list for me. The torch library allows me to create tensors for Part 2. \n",
    "\n",
    "I also extract the text file and then convert it to string. I then manipulate the string by replacing all the new line symbols with spaces so that my code doesn't read the new line symbol, cut off the header of the text file which is not part of the actual Constitution, and use the title function to make the beginning of every word a capital letter, so that when my code needs to choose a letter to start a word with, the sample of data it is pulling from is much larger than if I had just left the original document with only a few capital letters for proper nouns and the beginning of sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R8ymhbspXwM_"
   },
   "source": [
    "#Part 1#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XakFplNXqii1"
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.error import HTTPError\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Extract text file to bytes and then bytes to string\n",
    "Const = urlopen(\"https://www.usconstitution.net/const.txt\").read()\n",
    "encoding = 'utf-8'\n",
    "ConStr = Const.decode(encoding)\n",
    "#Cleans up string so it is just the Constutition, and capitalizes the beginning\n",
    "#of each word\n",
    "ConLine = ConStr.replace(\"\\n\", \" \")\n",
    "ConLine = ConLine[278::]\n",
    "ConLine = ConLine.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C4D5NGPHT3uw"
   },
   "source": [
    "Below, for the purposes of creating words in Parts 1 and 2, punctuation is unnecessary, so the translate and replace functions remove all the punctuation or turn it into the space character. I then create a blank array, and run a for loop through the no punctuation string, only adding a character to the blank array if it hasn't encountered it in the document previously. For ease of use, the array is sorted with the space character at the first index, and uppercase letters and then lowercase letters. Lastly, the amount of unique characters in the document is determined by taking the length of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r0crgVFbz7Gp"
   },
   "outputs": [],
   "source": [
    "#Removes unneccessary punctuation for creating words\n",
    "NoPunc = ConLine.translate({ord(i): None for i in ',\"[]\\/:();'})\n",
    "NoPunc = NoPunc.replace(\".\", \" \")\n",
    "#Creates set of unique characters\n",
    "unique = []\n",
    "for char in NoPunc[::]:\n",
    "    if char not in unique:\n",
    "        unique.append(char)\n",
    "unique.sort()\n",
    "n = len(unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ogZRG_v5XlkO"
   },
   "source": [
    "For the next section, we need to understand the creation of a word using one letter prediction as a Markov Process. \n",
    "First, a process is **Markov** if \n",
    "$$\n",
    "P[X_{k+1} = x_{k+1} \\;|\\; X_k = x_k, ..., X_0 = x_0 ] = P[X_{k+1} = x_{k+1} \\;|\\; X_k = x_k ].\n",
    "$$\n",
    "meaning that the probability that the next state is equal to some value is dependent only on the current state. Because we are only using the current letter to predict what the next letter should be, we can treat our predictions as being Markov. \n",
    "\n",
    "Because the process is Markov the collection of probabilites that one state will go to certain different state can be represened by a probability (stochastic) matrix, and populating it with probabilities. \n",
    "First we define a a **Stochastic Matrix** $Q$ as a real valued $n \\times n$ matrix such that\n",
    "\n",
    "- $Q_{i,j} \\in [0,1]$\n",
    "- The sum of each row is one. \n",
    "\n",
    "The probability matrix $Q$ is contstructed by placing the probability that the trajectory will go from state $i$ to state $j$ at $Q_{i,j}$, where $i$ is the row and $j$ is the column.\n",
    "\n",
    "Constructing our specific $Q$, the different states are the different unique characters, so $Q$ is a square matrix with the same size as the number of unqiue characters, with the same indexes for those states as their indices in the unique character array. Next to ensure that once a word is complete (i.e. the next predicted character is space) more words are not created, the probability is that the next character after the space is another space is 1, meaning that is the only outcome. Another way of saying this is that spaces are recursive. This is different than the probability for the character after the space in the document itself, but that isn't relevant to us. Since the space character is at index 0, $p[0,0]=1$\n",
    "\n",
    "To populate the rest of the probabilities, the code first uses regular expressions to search for each iteration of a certain character in Constitution string, and adds the index of that iteration to an array. The code then adds 1 to every value in the array of first characters indices to determine all the indices for every character that directly follows the initial character. The code then searches the main string for what character is at that index and adds that character to another array. The Counter function then parses that array to determine how many times each second character appears. A for loop records the indices for each second character in the unique characters matrix, and a final while loop sets $Q$ in the row corresponding to the first character, and the column corresponding to the second character to the probability, which is the iterations of that specific second character divided by the total amount of second characters. A while loop performs this for every character after the \"space\" character, which we manually determined the probability for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AVcO55o28IFT"
   },
   "outputs": [],
   "source": [
    "#Creates blank probability matrix\n",
    "p = np.zeros((n,n))\n",
    "p[0,0] = 1\n",
    "count = 1\n",
    "while count < len(unique): \n",
    "  #Creates an index array for each character iteration, and index for the following character\n",
    "  FirstLet = [m.start() for m in re.finditer(unique[count], NoPunc)]\n",
    "  SecondLet = [x+1 for x in FirstLet]\n",
    "  chars = []\n",
    "  i = 0 \n",
    "  #Adds each second letter to an array, and creates a dictionary of the amount of \n",
    "  #iterations for each of those letters\n",
    "  while i < len(SecondLet):\n",
    "    let = NoPunc[SecondLet[i]]\n",
    "    chars.append(let)\n",
    "    i = i + 1\n",
    "  total = len(chars)\n",
    "  instances = Counter(chars)\n",
    "  keys = list(instances.keys())\n",
    "  keyindex = []\n",
    "  #Creates a list of which letter each key corresponds to, which acts as the columns\n",
    "  #for the probability matrix\n",
    "  for x in keys:\n",
    "    if x in unique:\n",
    "      keyindex.append(unique.index(x))\n",
    "  d = 0\n",
    "  #Places the probability of each letter at the right index in the p matrix\n",
    "  while d < len(keyindex):\n",
    "    p[count,keyindex[d]] = instances[keys[d]]/total\n",
    "    d = d+1  \n",
    "  count = count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K_G4jZMNg0H0"
   },
   "source": [
    "Now that we have the probability matrix, we determine the trajectory, i.e. the list of states the process goes through, by multiplying Q times different probability vectors. We set our initial probability vector by choosing the index of a random capital letter. That index is the first value in the trajectory. In order to move through the Markov process, we need to determine the different probabilities of the possible next letters. Mathematically this is completed by taking the probability vector and multiplying it by the matrix, but in this case, since we know our starting point, we know the probability vector is $0$ everywhere except for the index of the first letter, where it is $1$. If we multiply that with $Q$, it performs the same function as taking the row of $Q$ with that index as an array, which is what the code does.\n",
    "\n",
    "The random.choice function then randomly chooses an integer between 0 and n, where n is the length of the unqiue characters, so essentially the random.choice function is choosing an index. The choice is random, but the probability of one index being chosen over another is pulled from the probability previous determined from $Q$. This index is then added to the trajectory, and the process repeats, with the new character index acting as the current state. Thus, the new probability vector is also $0$ except for $1$ and the index of the current state, and we can again simply extract that row of the probability matrix. A while loop repeats this function until the new character is a space i.e. it has an index = 0, after which the loops breaks, signifying the completion of a word. \n",
    "\n",
    "Lastly, the characters corresponding to each of the indices contained in the trajectory list are added in order to an empty array, and then those characters are joined together to form a string. That string is added to an array of words, and this process repeats 100 times to form 100 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10648,
     "status": "ok",
     "timestamp": 1576011742230,
     "user": {
      "displayName": "Zach Pankratz",
      "photoUrl": "",
      "userId": "13420361187636820967"
     },
     "user_tz": 480
    },
    "id": "yIn99DAzc1e5",
    "outputId": "76dc4558-a3aa-4a86-cea5-693266c2de9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go ',\n",
       " 'Grgar ',\n",
       " 'Gisonraks ',\n",
       " 'Atusis ',\n",
       " 'Kenirtallespo ',\n",
       " 'Mallecie ',\n",
       " 'Tomitatorsore ',\n",
       " 'Unciebmis ',\n",
       " 'Fiteng ',\n",
       " 'Hatatingretallay ',\n",
       " 'Ondmeateviony ',\n",
       " 'Foiesthajon ',\n",
       " 'Coratotityirseppatin ',\n",
       " 'By ',\n",
       " 'Me ',\n",
       " 'Onticters ',\n",
       " 'He ',\n",
       " 'Mirechr ',\n",
       " 'She ',\n",
       " 'Norctss ',\n",
       " 'Ma ',\n",
       " 'Novenhe ',\n",
       " 'Ges ',\n",
       " 'Quiaslall ',\n",
       " 'Qurersigrt ',\n",
       " 'Butand ',\n",
       " 'For ',\n",
       " 'Har ',\n",
       " 'Fir ',\n",
       " 'Inkeid ',\n",
       " 'Unsd ',\n",
       " 'Co ',\n",
       " 'Yed ',\n",
       " 'Qusamor ',\n",
       " 'Frt ',\n",
       " 'Rel ',\n",
       " 'Lerus ',\n",
       " 'Lecus ',\n",
       " 'Un ',\n",
       " 'Pr ',\n",
       " 'May ',\n",
       " 'Juced ',\n",
       " 'Jucerim ',\n",
       " 'Hal ',\n",
       " 'Yen ',\n",
       " 'Nores ',\n",
       " 'Higroume ',\n",
       " 'Rentidy ',\n",
       " 'Thames ',\n",
       " 'Mat ',\n",
       " 'Ke ',\n",
       " 'Wited ',\n",
       " 'Ye ',\n",
       " 'No ',\n",
       " 'Male ',\n",
       " 'Ald ',\n",
       " 'Coriors ',\n",
       " 'Ans ',\n",
       " 'By ',\n",
       " 'Literiore ',\n",
       " 'It ',\n",
       " 'Putindsioncke ',\n",
       " 'Viowictibe ',\n",
       " 'Than ',\n",
       " 'Iteawer ',\n",
       " 'Hongsanenay ',\n",
       " 'Fot ',\n",
       " 'Kiche ',\n",
       " 'Thepouse ',\n",
       " 'Carar ',\n",
       " 'Prwes ',\n",
       " 'Th ',\n",
       " 'Und ',\n",
       " 'Pred ',\n",
       " 'Fithe ',\n",
       " 'Ans ',\n",
       " 'Be ',\n",
       " 'Jud ',\n",
       " 'Vat ',\n",
       " 'Gome ',\n",
       " 'Grorul ',\n",
       " 'Ing ',\n",
       " 'Hatecor ',\n",
       " 'On ',\n",
       " 'Ins ',\n",
       " 'Jucivequre ',\n",
       " 'Nomes ',\n",
       " 'Unthootississpry ',\n",
       " 'Re ',\n",
       " 'Matiginal ',\n",
       " 'Toy ',\n",
       " 'Rer ',\n",
       " 'Nomicepid ',\n",
       " 'Comer ',\n",
       " 'Surtidin ',\n",
       " 'No ',\n",
       " 'Cos ',\n",
       " 'Ye ',\n",
       " 'Bert ',\n",
       " 'Ex ']"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist = []\n",
    "w = 100\n",
    "j = 0\n",
    "while j < w:\n",
    "  #Starts the word at a random capital letter index\n",
    "  x = np.random.randint(12,36)\n",
    "  trajectory = [x]\n",
    "  nextLet = [x]\n",
    "  #Randomly chooses the next letter index, based on the probability of the\n",
    "  #previous letter, until it reachs the \"space\" index, and adds it to an array\n",
    "  while nextLet[0] != 0:\n",
    "    start = p[nextLet[0],:]\n",
    "    nextLet = np.random.choice(n, 1, p=start)\n",
    "    trajectory.append(nextLet[0])\n",
    "  f = []\n",
    "  #Takes the indices that were chosen and turns them into their corresponding \n",
    "  #letters, and then combines those letters into a string \n",
    "  for x in trajectory:\n",
    "    f.append(unique[x])\n",
    "    str1 = ''.join(f)\n",
    "  wordlist.append(str1)\n",
    "  j = j + 1\n",
    "wordlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wSpT7nd_nvG2"
   },
   "source": [
    "These are the 100 words my function produced.\n",
    "\n",
    "['Go ', 'Grgar ', 'Gisonraks ', 'Atusis ', 'Kenirtallespo ', 'Mallecie ', 'Tomitatorsore ', 'Unciebmis ', 'Fiteng ', 'Hatatingretallay ', 'Ondmeateviony ', 'Foiesthajon ', 'Coratotityirseppatin ', 'By ', 'Me ', 'Onticters ', 'He ', 'Mirechr', 'She ', 'Norctss ', 'Ma', 'Novenhe ', 'Ges ', 'Quiaslall ', 'Qurersigrt ', 'Butand', 'For ', 'Har ', 'Fir ', 'Inkeid ', 'Unsd ', 'Co ', 'Yed ', 'Qusamor ', 'Frt ', 'Rel ', 'Lerus ', 'Lecus ', 'Un ', 'Pr ', 'May ' , 'Juced ', 'Jucerim ', 'Hal ', 'Yen ', 'Nores ', 'Higroume ', 'Rentidy ', 'Thames ', 'Mat ', 'Ke ', 'Wited ', 'Ye ', 'No ', 'Male ', 'Ald ', 'Coriors ', 'Ans ', 'By ', 'Literiore ', 'It ', 'Putindsioncke ', 'Viowictibe ', 'Than ',  'Iteawer ', 'Hongsanenay ', 'Fot ', 'Kiche ', 'Thepouse ', 'Carar ', 'Prwes ', 'Th ', 'Und ', 'Pred ', 'Fithe ', 'Ans ', 'Be ', 'Jud ', 'Vat ', 'Gome ', 'Grorul ', 'Ing ', 'Hatecor ', 'On ', 'Ins ', 'Jucivequre ', 'Nomes ',  'Unthootississpry ', 'Re ', 'Matiginal ', 'Toy ', 'Rer ', 'Nomicepid ', 'Comer',\n",
    " 'Surtidin ', 'No ', 'Cos ', 'Ye ', 'Bert ', 'Ex ']\n",
    "\n",
    " To determine if they were actually words, I checked these words against the Constitution text file. If the words did not appear in the Constitution text file, then I didn't treat it as an actual word.  The code runs a for loop for every word \"hallucinated\". It checks if the word is within the Constitution string, and if it finds it, it adds that word to an array and counts it. This code determined that there were 14 words hallucinated, and they are as follows. \n",
    " \n",
    "['By ', 'He ', 'For ', 'May ', 'No ', 'Male ', 'By ', 'It ', 'Than ', 'Th ', 'Be ', 'On ', 'No ', 'Ex ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 644,
     "status": "ok",
     "timestamp": 1576012580088,
     "user": {
      "displayName": "Zach Pankratz",
      "photoUrl": "",
      "userId": "13420361187636820967"
     },
     "user_tz": 480
    },
    "id": "lmPv-f936ZFt",
    "outputId": "423fe325-9866-4b89-ac38-fa3ef9ddf505"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14,\n",
       " ['By ',\n",
       "  'He ',\n",
       "  'For ',\n",
       "  'May ',\n",
       "  'No ',\n",
       "  'Male ',\n",
       "  'By ',\n",
       "  'It ',\n",
       "  'Than ',\n",
       "  'Th ',\n",
       "  'Be ',\n",
       "  'On ',\n",
       "  'No ',\n",
       "  'Ex '])"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amount = 0\n",
    "actualWords = []\n",
    "#Check the words in the set of words to see if they are in the Constitution string\n",
    "for x in wordlist:\n",
    "  if x in NoPunc:\n",
    "    amount = amount + 1\n",
    "    actualWords.append(x)\n",
    "amount, actualWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QyxD8R60YGoT"
   },
   "source": [
    "#Part 2#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a9lG3rGCuooA"
   },
   "source": [
    "Because this section requires the same information, i.e. just letters and spaces, and no punctuation, the initial strings and unique character arrays are the same in this part as in Part 1.\n",
    "\n",
    "We still need to justify the creation of a word using two letter prediction as a Markov Process. \n",
    "As a reminder, a process is **Markov** if \n",
    "$$\n",
    "P[X_{k+1} = x_{k+1} \\;|\\; X_k = x_k, ..., X_0 = x_0 ] = P[X_{k+1} = x_{k+1} \\;|\\; X_k = x_k ].\n",
    "$$\n",
    "meaning that the probability that the next state is equal to some value is dependent only on the current state. We are treating the current state as having two components, the two preceding letters, but those two components still act together as one state, which can be used to predict what the next letter should be, and thus our predictions follow the Markov process. \n",
    "\n",
    "The probability matrix must have space for 3 components then, so the probabilities must then be stored in a tensor, which can be understood a matrix of matrices. The probability that based on the current state with components $i$ and $j$ ($i$ being the state of the first character, and $j$ being the state of the second) the next state will be $k$, is stored in $Q_{i,j,k}$, where $i$ is the matrix index, $j$ is the row in that matrix, and $k$ is the column in that row. \n",
    "\n",
    "Given that we start with a capital letter, the probability that the \"space\" character is recursive must still be 1. Otherwise, if the second character is a space, and the third character is not a space, a new word is started, which defeats the purpose of creating a singular word. Thus the probability is 1 that for any first letter, if the second character is a space, the third character is a space, which is summarized by $p2[:,0,0] = 1$\n",
    "\n",
    "This code begins similarily to the code in part 1, where the second characters are stored in an array and the Counter function produces a dictionary that gives the amount of iterations for each secondary character. However, it then goes a level deeper. The code then creates arrays of the indices for each respective iteration for a second character, and the indices of the character that directly follows them, the third character. The indices in that third letter array then are changed into their corresponding characters, and those third characters are aggregated in another counter to determine how many times they each iterate. The index of those third characters in the unique characters matrix is then placed in another array, and another while loop places each of the probabilities for each unique character index in the corresponding first letter matrix and second letter row that the while loops are currently on. The probability is the amount of iterations for that particular third character, divided by the total amount of third characters for the particular first and second characters. \n",
    "\n",
    "Using this methodology, there will be some rows within matrices that do not sum to 1, and instead are all zeroes. This is okay because those matrix/row pairs correspond to first and second letter pairs that cannot create words as defined by the Constitution string. The first and second characters \"Bz\" will not produce a word, and thus no probability of a third character needs to be calculated as that probability will never be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qXu_CdWwYNFX"
   },
   "outputs": [],
   "source": [
    "#Creates a blank tensor\n",
    "p2 = torch.zeros([n, n, n], dtype=torch.float64)\n",
    "p2[:,0,0] = 1\n",
    "count1 = 1\n",
    "while count1 < n: \n",
    "  #Creates an index array for each character iteration, and index of following character\n",
    "  FL = [m.start() for m in re.finditer(unique[count1], NoPunc)]\n",
    "  SL = [x+1 for x in FL]\n",
    "  chars = []\n",
    "  i = 0 \n",
    "  #Adds each second letter to an array, and creates a dictionary of the amount of \n",
    "  #iterations for each of those letters\n",
    "  while i < len(SL):\n",
    "    let = NoPunc[SL[i]]\n",
    "    chars.append(let)\n",
    "    i = i + 1\n",
    "  instances = Counter(chars)\n",
    "  keys = list(instances.keys())\n",
    "  keys.sort()\n",
    "  total = len(chars)\n",
    "  count2 = 0\n",
    "  #Creates an index array for each secondary character iteration after the first,\n",
    "  #and an array of the character that follows those secondary characters  \n",
    "  while count2 < len(keys):\n",
    "    z = keys[count2]\n",
    "    z1 = unique.index(z)\n",
    "    SL2 = [m.start() for m in re.finditer(keys[count2], NoPunc)]\n",
    "    SL3 = [x for x in SL if x in SL2]\n",
    "    TL = [x+1 for x in SL3]\n",
    "    chars2 = []\n",
    "    j = 0 \n",
    "    #Adds each third letter to an array, and creates a dictionary of the amount of \n",
    "    #iterations for each of those letters\n",
    "    while j < len(TL):\n",
    "      let = NoPunc[TL[j]]\n",
    "      chars2.append(let)\n",
    "      j = j + 1\n",
    "    total2 = len(chars2)\n",
    "    instances2 = Counter(chars2)\n",
    "    keys2 = list(instances2.keys())\n",
    "    keys2.sort()\n",
    "    keyindex2 = []\n",
    "    #Creates a list of which letter each key corresponds to, which acts as the columns\n",
    "    #for the probability matrix\n",
    "    for x in keys2:\n",
    "      if x in unique:\n",
    "        keyindex2.append(unique.index(x))\n",
    "    d = 0\n",
    "    #Places the probability of each letter at the right index in the y matrix\n",
    "    while d < len(keyindex2):\n",
    "      p2[count1, z1, keyindex2[d]] = instances2[keys2[d]]/total2\n",
    "      d = d+1  \n",
    "    count2 = count2 + 1\n",
    "  count1 = count1 + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fWa9qvI-LdLo"
   },
   "source": [
    "The code methodology for creating a word starts very similar to the code in Part 1, an index for a random capital letter is chosen, and then code uses the one letter prediction model to find the index of the second letter of the word. The trajectory array is appended to hold those two indices, and first and second characters are also added to a holding array. Using the same methodology as before, selecting the correct row in the probability matrix to find the probability given a current state, the system pulls the code for the given first and second letter indices. The code then moves the second letter index to become the first level index, and randomly chooses a new second letter out of the unique character index based on probability given previously. The new second character index is added to the trajectory as a third character, and the while loop continues this process until the new second character index is the space index, signaling the end of a word. This collection of indices is then added to a new array as their character counter parts, and those characters are added together to form a string. That string is then added to an array of words. A while loop performs this process 100 times for 100 words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21711,
     "status": "ok",
     "timestamp": 1576011753311,
     "user": {
      "displayName": "Zach Pankratz",
      "photoUrl": "",
      "userId": "13420361187636820967"
     },
     "user_tz": 480
    },
    "id": "Aez5c8oDTi9x",
    "outputId": "6f773491-e56c-44ce-f080-43a6749b0ee4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chost ',\n",
       " 'Year ',\n",
       " 'Of ',\n",
       " 'Live ',\n",
       " 'Reprem ',\n",
       " 'No ',\n",
       " 'Con ',\n",
       " 'Hisding ',\n",
       " 'Price ',\n",
       " 'Legis ',\n",
       " 'Geof ',\n",
       " 'Namentator ',\n",
       " 'Relicurtiont ',\n",
       " 'For ',\n",
       " 'Boted ',\n",
       " 'Severes ',\n",
       " 'House ',\n",
       " 'Presingres ',\n",
       " 'Inhall ',\n",
       " 'Comminaturnatess ',\n",
       " 'Offer ',\n",
       " 'Ove ',\n",
       " 'Grall ',\n",
       " 'The ',\n",
       " 'Whold ',\n",
       " 'Sam ',\n",
       " 'Havess ',\n",
       " 'Exes ',\n",
       " 'Yeasese ',\n",
       " 'Holl ',\n",
       " 'Gresent ',\n",
       " 'Jurnme ',\n",
       " 'Cent ',\n",
       " 'Govid ',\n",
       " 'Prece ',\n",
       " 'Ball ',\n",
       " 'Judent ',\n",
       " 'Yeasen ',\n",
       " 'Jent ',\n",
       " 'Coinside ',\n",
       " 'If ',\n",
       " 'Vice ',\n",
       " 'The ',\n",
       " 'Nothe ',\n",
       " 'Have ',\n",
       " 'Hels ',\n",
       " 'Menstiestiongst ',\n",
       " 'Fority ',\n",
       " 'Higisions ',\n",
       " 'The ',\n",
       " 'For ',\n",
       " 'Decto ',\n",
       " 'Lainey ',\n",
       " 'Greetes ',\n",
       " 'He ',\n",
       " 'A ',\n",
       " 'Repres ',\n",
       " 'Mores ',\n",
       " 'Legaing ',\n",
       " 'They ',\n",
       " 'Kings ',\n",
       " 'Law ',\n",
       " 'On ',\n",
       " 'Forson ',\n",
       " 'Jureentice ',\n",
       " 'Lains ',\n",
       " 'Res ',\n",
       " 'Yeartion ',\n",
       " 'Force ',\n",
       " 'Jus ',\n",
       " 'Keent ',\n",
       " 'Make ',\n",
       " 'Yeary ',\n",
       " 'Thall ',\n",
       " 'The ',\n",
       " 'Shate ',\n",
       " 'Yeased ',\n",
       " 'Cited ',\n",
       " 'Keeturnme ',\n",
       " 'On ',\n",
       " 'Viclediniall ',\n",
       " 'Geof ',\n",
       " 'Of ',\n",
       " 'Quor ',\n",
       " 'The ',\n",
       " 'Wity ',\n",
       " 'Kinate ',\n",
       " 'Juns ',\n",
       " 'Whoose ',\n",
       " 'Kin ',\n",
       " 'Cit ',\n",
       " 'Hous ',\n",
       " 'Leguls ',\n",
       " 'Wholver ',\n",
       " 'Ques ',\n",
       " 'Jount ',\n",
       " 'Quall ',\n",
       " 'Gil ',\n",
       " 'Unlesisers ',\n",
       " 'Wribines ']"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist2 = []\n",
    "w = 100\n",
    "j = 0\n",
    "while j < w:\n",
    "  #Chooses a random capital index, and chooses a second letter index randomly \n",
    "  #based on the probabilities in part 1\n",
    "  x = np.random.randint(12,36)\n",
    "  trajectory2 = [x]\n",
    "  start = p[x,:]\n",
    "  nextLet = np.random.choice(n, 1, p=start)\n",
    "  trajectory2.append(nextLet[0])\n",
    "  nextLet2 = [trajectory2[0], trajectory2[1]]\n",
    "  #Randomly chooses the next letter index, based on the probability of the\n",
    "  #previous 2 letter indices, until it reachs the \"space\" index, and adds it to\n",
    "  #the array with the previous indices. \n",
    "  while nextLet2[1] != 0:\n",
    "    start1 = p2[nextLet2[0],nextLet2[1],:]\n",
    "    start2 = start1.numpy().reshape(62)\n",
    "    nextLet2[0] = nextLet2[1]\n",
    "    nextLet2[1] = np.random.choice(n, 1, p=start2)\n",
    "    trajectory2.append(nextLet2[1][0])\n",
    "  f = []\n",
    "  #Takes the indices that were chosen and turns them into their corresponding \n",
    "  #letters, and then combines those letters into a string \n",
    "  for x in trajectory2:\n",
    "    f.append(unique[x])\n",
    "    str2 = ''.join(f)\n",
    "  wordlist2.append(str2)\n",
    "  j = j + 1\n",
    "wordlist2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lP2q-W6SOC3a"
   },
   "source": [
    "The 100 words the 2-letter prediction code \"hallucinated\" were: \n",
    "\n",
    "['Chost ',\n",
    " 'Year ',\n",
    " 'Of ',\n",
    " 'Live ',\n",
    " 'Reprem ',\n",
    " 'No ',\n",
    " 'Con ',\n",
    " 'Hisding ',\n",
    " 'Price ',\n",
    " 'Legis ',\n",
    " 'Geof ',\n",
    " 'Namentator ',\n",
    " 'Relicurtiont ',\n",
    " 'For ',\n",
    " 'Boted ',\n",
    " 'Severes ',\n",
    " 'House ',\n",
    " 'Presingres ',\n",
    " 'Inhall ',\n",
    " 'Comminaturnatess ',\n",
    " 'Offer ',\n",
    " 'Ove ',\n",
    " 'Grall ',\n",
    " 'The ',\n",
    " 'Whold ',\n",
    " 'Sam ',\n",
    " 'Havess ',\n",
    " 'Exes ',\n",
    " 'Yeasese ',\n",
    " 'Holl ',\n",
    " 'Gresent ',\n",
    " 'Jurnme ',\n",
    " 'Cent ',\n",
    " 'Govid ',\n",
    " 'Prece ',\n",
    " 'Ball ',\n",
    " 'Judent ',\n",
    " 'Yeasen ',\n",
    " 'Jent ',\n",
    " 'Coinside ',\n",
    " 'If ',\n",
    " 'Vice ',\n",
    " 'The ',\n",
    " 'Nothe ',\n",
    " 'Have ',\n",
    " 'Hels ',\n",
    " 'Menstiestiongst ',\n",
    " 'Fority ',\n",
    " 'Higisions ',\n",
    " 'The ',\n",
    " 'For ',\n",
    " 'Decto ',\n",
    " 'Lainey ',\n",
    " 'Greetes ',\n",
    " 'He ',\n",
    " 'A ',\n",
    " 'Repres ',\n",
    " 'Mores ',\n",
    " 'Legaing ',\n",
    " 'They ',\n",
    " 'Kings ',\n",
    " 'Law ',\n",
    " 'On ',\n",
    " 'Forson ',\n",
    " 'Jureentice ',\n",
    " 'Lains ',\n",
    " 'Res ',\n",
    " 'Yeartion ',\n",
    " 'Force ',\n",
    " 'Jus ',\n",
    " 'Keent ',\n",
    " 'Make ',\n",
    " 'Yeary ',\n",
    " 'Thall ',\n",
    " 'The ',\n",
    " 'Shate ',\n",
    " 'Yeased ',\n",
    " 'Cited ',\n",
    " 'Keeturnme ',\n",
    " 'On ',\n",
    " 'Viclediniall ',\n",
    " 'Geof ',\n",
    " 'Of ',\n",
    " 'Quor ',\n",
    " 'The ',\n",
    " 'Wity ',\n",
    " 'Kinate ',\n",
    " 'Juns ',\n",
    " 'Whoose ',\n",
    " 'Kin ',\n",
    " 'Cit ',\n",
    " 'Hous ',\n",
    " 'Leguls ',\n",
    " 'Wholver ',\n",
    " 'Ques ',\n",
    " 'Jount ',\n",
    " 'Quall ',\n",
    " 'Gil ',\n",
    " 'Unlesisers ',\n",
    " 'Wribines ']\n",
    "\n",
    " In the same way as in Part 1, I search for each word in the Constitution string, and add the word to an array and count it if it is found. The following 22 actual words were produced by the 2-letter prediction, so we find that 2-letter prediction is better at creating real words than 1-letter prediction.\n",
    "\n",
    "  ['Year ',\n",
    "  'Of ',\n",
    "  'No ',\n",
    "  'For ',\n",
    "  'House ',\n",
    "  'The ',\n",
    "  'If ',\n",
    "  'Vice ',\n",
    "  'The ',\n",
    "  'Have ',\n",
    "  'The ',\n",
    "  'For ',\n",
    "  'He ',\n",
    "  'A ',\n",
    "  'They ',\n",
    "  'Law ',\n",
    "  'On ',\n",
    "  'Make ',\n",
    "  'The ',\n",
    "  'On ',\n",
    "  'Of ',\n",
    "  'The ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 351,
     "status": "ok",
     "timestamp": 1576021845044,
     "user": {
      "displayName": "Zach Pankratz",
      "photoUrl": "",
      "userId": "13420361187636820967"
     },
     "user_tz": 480
    },
    "id": "vmEpqrzNubey",
    "outputId": "aaae72bd-e7b2-4d92-f100-6a2d969b2421"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22,\n",
       " ['Year ',\n",
       "  'Of ',\n",
       "  'No ',\n",
       "  'For ',\n",
       "  'House ',\n",
       "  'The ',\n",
       "  'If ',\n",
       "  'Vice ',\n",
       "  'The ',\n",
       "  'Have ',\n",
       "  'The ',\n",
       "  'For ',\n",
       "  'He ',\n",
       "  'A ',\n",
       "  'They ',\n",
       "  'Law ',\n",
       "  'On ',\n",
       "  'Make ',\n",
       "  'The ',\n",
       "  'On ',\n",
       "  'Of ',\n",
       "  'The '])"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amount2 = 0\n",
    "actualWords2 = []\n",
    "#Check the words in the set of words to see if they are in the Consitution string\n",
    "for x in wordlist2:\n",
    "  if x in NoPunc:\n",
    "    amount2 = amount2 + 1\n",
    "    actualWords2.append(x)\n",
    "amount2, actualWords2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dr90mozRQzJ-"
   },
   "source": [
    "#Part 3#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v-9ZYvC5Rlk9"
   },
   "source": [
    "Because the goal is to \"hallucinate\" sentences instead of words, and punctuation counts as words, the Constitution string must be manipulated in a different way. Instead of getting rid of all the punctuation, the code below replaces all the punctuation with the same punctuation but surrounded by spaces. This is done because the split function separates the file into a list a substrings, and it splits the substrings if there is a space between them. In order to create a list of the unique words in the file, the list of all the words in the document is converted into a set, which automatically gets rid of all duplicates. This set is then converted back into a list so it can be indexed. For ease of use, the unique words are sorted alphabetically (with punctuation coming first), and the total amount of unique words is found by taking the length of the unique words list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3fizw5ykTpaX"
   },
   "outputs": [],
   "source": [
    "#Makes sure puncutation is treated as a word by when the document is split by spaces\n",
    "PuncSep = ConLine.replace(\".\", \" . \")\n",
    "PuncSep = PuncSep.replace(\",\", \" , \")\n",
    "PuncSep = PuncSep.replace(\";\", \" ; \")\n",
    "PuncSep = PuncSep.replace(\":\", \" : \")\n",
    "PuncSep = PuncSep.replace(\")\", \" ) \")\n",
    "PuncSep = PuncSep.replace(\"(\", \" ( \")\n",
    "PuncSep = PuncSep.replace('\"', ' \" ')\n",
    "PuncSep = PuncSep.replace('-', ' - ')\n",
    "#Puts all the words into an array, and then makes set of 1 iteration of each word\n",
    "allWords = PuncSep.split()\n",
    "UW = list(set(allWords))\n",
    "UW.sort()\n",
    "num = len(UW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_j9LUV-CTB9R"
   },
   "source": [
    "In terms of creating the probability matrix, this code is very similar to creating the probability matrix in Part 1. A blank probability matrix with size and rows/columns corresponding to the indices of the unique words list is created. Then a for loop searches the list of all words for each iteration of a word, and adds those indices to an array, as well as the index of the words that follows the iteration of the first word. The words that are at those second word indices are then put into an array. The only exception to this is the word/puncuation \".\", which is the last \"word\" as thus doesn't have a second word following it. In this case, every word following a \".\" except for the last \".\" are added to an array. The counter function then creates a dictionary which delineates how many times each second word occurs after the first word. The index for each second word in the unique words array are determined by using the index funtion on the unique words list, and these indices are added to an index array. Lastly, the code goes through each of those indices and places the probability for that words at that index, in corresponding row for the original first word. The probability is the amount of iterations of the second word divided by the total amount of second words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ny3zP-1yZTdL"
   },
   "outputs": [],
   "source": [
    "p3 = np.zeros((num,num))\n",
    "count3 = 0\n",
    "while count3 < num: \n",
    "  FW = [i for i, e in enumerate(allWords) if e == UW[count3]]\n",
    "  SW = [x+1 for x in FW]\n",
    "  allWords[SW[0]]\n",
    "  nextWords = []\n",
    "  i = 0 \n",
    "  #Adds each second word to an array, and creates a dictionary of the amount of \n",
    "  #iterations for each of those words\n",
    "  if count3 == 5:\n",
    "    while i + 1 < len(SW):\n",
    "         w = allWords[SW[i]]\n",
    "         nextWords.append(w)\n",
    "         i = i + 1\n",
    "  else: \n",
    "    while i < len(SW):\n",
    "      w = allWords[SW[i]]\n",
    "      nextWords.append(w)\n",
    "      i = i + 1\n",
    "  total3 = len(nextWords)\n",
    "  instances3 = Counter(nextWords)\n",
    "  keys3 = list(instances3.keys())\n",
    "  keyindex3 = []\n",
    "  #Creates a list of which word each key corresponds to, which acts as the columns\n",
    "  #for the probability matrix\n",
    "  for x in keys3:\n",
    "    if x in UW:\n",
    "      keyindex3.append(UW.index(x))\n",
    "  d = 0\n",
    "  #Places the probability of each word at the right index in the p matrix\n",
    "  while d < len(keyindex3):\n",
    "    p3[count3,keyindex3[d]] = instances3[keys3[d]]/total3\n",
    "    d = d+1\n",
    "  count3 = count3 + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7hGjU5yqYfGl"
   },
   "source": [
    "The methodology for contructing a sentence also bears a lot of similarity to the methodology in Part 1. The unique words index for a random word (non-punctuation or number) is chosen to start the sentence. I originally had each sentence start with a random words chosen based on the probability of which words were most likely to start a sentence (i.e. follow a period) but for some reason that tended to generate very long or very short sentences. That random word index is then added to the trajectory, and the row of the probability matrix corresponding to that word index is selected. A second word index is then randomly chosen based on the probability from the first word index. The second word index becomes the new current state, and the process repeats itself until the new word generated is a period, which signals the end of a sentence. Those word indices are then converted into their actual word counterparts in the unique word list, and added a new array. The collection of substring in that new array is then added together to create one big string, adding a space between each substring. That larger string is then added to an array of sentences. The while loop that surrounds this code makes sure that the process is performed 5 times for 5 sentences. \n",
    "\n",
    "The sentences the code produced were: \n",
    "\n",
    "**['Disapproved By The Vice President , Expel A Smaller Number Of Any State , He Shall Be The Government Of The Removal Of The Authority Over Those Of The Authority Of Another : But If No Capitation , Except In The Right To Choose Their Journal .', \\\\\n",
    " 'Persons Voted For The Vice President .', \\\\\n",
    " 'Terms Of Two Or Affirmation , Open Court , Are Eighteen Years A Resident Within The Common Defence .', \\\\\n",
    " 'Seventeenth Day To Raise And Inferior Courts , Determines By The Seat Of President Pro Tempore Of A President Pro Tempore , Punish Its Jurisdiction Thereof , The Vice - President And Consuls ; And Fact , Become President .', \\\\\n",
    " 'Thereby , The Constitution Of The Executive Power To The Vice President ; And Nays Of Senators And For More Than One Supreme Court ; He Was Elected By A President Of March Next Session .']**\n",
    "\n",
    "These sentences don't much sense, but they aren't complete gibberish either. One issue that I noticed was reading punctuation as a word led to run on sentences. Additionally, there were a wider variety of words which followed puntuation, as oppossed to normal words, so sentences didn't make as much sense because adding punctuation was essentially like a restart button to the sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22873,
     "status": "ok",
     "timestamp": 1576011754497,
     "user": {
      "displayName": "Zach Pankratz",
      "photoUrl": "",
      "userId": "13420361187636820967"
     },
     "user_tz": 480
    },
    "id": "3I70ipsgGT5_",
    "outputId": "f291c3b2-7ea3-4e99-a406-13aa1ff6c0cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Disapproved By The Vice President , Expel A Smaller Number Of Any State , He Shall Be The Government Of The Removal Of The Authority Over Those Of The Authority Of Another : But If No Capitation , Except In The Right To Choose Their Journal .',\n",
       " 'Persons Voted For The Vice President .',\n",
       " 'Terms Of Two Or Affirmation , Open Court , Are Eighteen Years A Resident Within The Common Defence .',\n",
       " 'Seventeenth Day To Raise And Inferior Courts , Determines By The Seat Of President Pro Tempore Of A President Pro Tempore , Punish Its Jurisdiction Thereof , The Vice - President And Consuls ; And Fact , Become President .',\n",
       " 'Thereby , The Constitution Of The Executive Power To The Vice President ; And Nays Of Senators And For More Than One Supreme Court ; He Was Elected By A President Of March Next Session .']"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentList = []\n",
    "w = 5\n",
    "j = 0\n",
    "begin = p3[5,:]\n",
    "while j < w:\n",
    "  #Starts the sentence at a random word (non-punctuation) index\n",
    "  x = np.random.randint(38,1174)\n",
    "  trajectory3 = [x]\n",
    "  nWord = [x]\n",
    "  #Randomly chooses the next word index, based on the probability of the\n",
    "  #previous word, until it reachs the \"period\" index, and adds it to an array\n",
    "  while nWord[0] != 5:\n",
    "    start3 = p3[nWord[0],:].reshape(num)\n",
    "    nWord = np.random.choice(num, 1, p=start3)\n",
    "    trajectory3.append(nWord[0])\n",
    "  f = []\n",
    "  #Takes the indices that were chosen and turns them into their corresponding \n",
    "  #words, and then combines those words into a string \n",
    "  for x in trajectory3:\n",
    "    f.append(UW[x])\n",
    "    str1 = ' '.join(f)\n",
    "  sentList.append(str1)\n",
    "  j = j + 1\n",
    "sentList"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Zachary_Pankratz_Final_HW10_EE502.ipynb",
   "provenance": [
    {
     "file_id": "1XJQbxmI4Svqyv9VclYq5MiGhfu1YC3sZ",
     "timestamp": 1575664434835
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
