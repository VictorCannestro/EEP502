{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T16:05:23.746666Z",
     "start_time": "2019-09-24T16:05:23.741461Z"
    }
   },
   "source": [
    "## EE 502 P: Analytical Methods for Electrical Engineering\n",
    "    \n",
    "# Homework 10: Review\n",
    "## Due 15 December, 2019 at 11:59 PM\n",
    "\n",
    "## Name: Kyle Hadley\n",
    "\n",
    "Copyright &copy; 2019, University of Washington\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Instructions**: Choose **<u>one</u>** of the following problems. Solve the problem and then write up your solution in a stand alone Jupyter Notebook. Your notebook should have the following elements:\n",
    "\n",
    "- Problem statement\n",
    "- Mathematical description of the solution\n",
    "- Executable code, commented, clear code\n",
    "\n",
    "You will be graded on how well your notebook reads like a nicely formated, well written report. You must:\n",
    "\n",
    "- Write mathematical descriptions using complete sentences, paragraphs, and LaTeX formulas. \n",
    "- Comment your code as necessary, with a description of what each function does and all major steps.\n",
    "- Label plots axes, use legends, and use plot titles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement: Hallucinating the Constitution\n",
    "\n",
    "Consider the constitution of the United States:\n",
    "\n",
    "> https://www.usconstitution.net/const.txt .\n",
    "\n",
    "This document contains upper- and lower-case letters, numbers, and basic punctuation. \n",
    "\n",
    "**One letter prediction:**\n",
    "\n",
    "1. Find the set of all characters used in the document. Call the number of characters $n$. \n",
    "2. Create an $n \\times n$ matrix whose $i,j$ entry is the probability that the next character is $j$ given that the current character is $i$. Estimate this probability by looking at all occurrences of character $i$ in the document and the number of times character $j$ immediately follows it. \n",
    "3. Simulate this system as a Markov chain that starts with an arbitrary capital letter and continues until it gets to a space. Produce $100$ random \"words\" this way. How many of them are actual works (use a [Scrabble dictionary](https://scrabble.hasbro.com/en-us/tools#dictionary) if you are not certain whether a given sequence is a word). \n",
    "\n",
    "**Two letter prediction:**\n",
    "\n",
    "1. Create an $n \\times n \\times n$ tensor whose $i,j,k$ entry is the probability that the next character is $k$ given that the current character is $j$ and the previous character is $i$. Use the document to empirically find these probabilities. \n",
    "2. Use this model to construct random words. \n",
    "\n",
    "**Sentence prediction:**\n",
    "\n",
    "Do a one word prediction, but use all the unique *words* in the document. Hallucinate sentences. Consider a punctuation mark as a word.\n",
    "\n",
    "**Notes:** Use `open` and `file.read` to read in the file as a string. For the sentence. Use `replace` to add space before punctuation and then `split()` to turn the string into a list. Use a `DiGraph` from the `networkx` library to store the data. Note that you can make weighted edges by adding data to the edges, as in [this document](https://networkx.github.io/documentation/stable/auto_examples/drawing/plot_weighted_graph.html).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Input and Structure\n",
    "\n",
    "The first step is to import the necessary libraries that will be used for the problem statement. Then seed the random function with a value of $1$, such that our solutions can be repeated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys\n",
    "\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "# np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text version of the US Constituion is saved as a local file called `const.txt`. This file is read-in and saved to a string (`text_file`) containing the entire text of the US Constitution.\n",
    "\n",
    "A series of `replace` calls are made to add spaces around non-alphanumeric characters that appear within the Constitution. As an example, every comma has a space added before it. By adding these additional spaces, the `split` function can be called to generate an array, $W$, of the words in the text file. This array will be used in the 3rd part of the solution.\n",
    "\n",
    "From $W$, the set of all unique words that appear in the US Constituion $X$ is defined as\n",
    "\n",
    "$$ X = \\{word : word \\in \\text{US Consitution}\\}.$$\n",
    "\n",
    "The set $X$ is calculating using numpy's `unique(array)` function which returns the unique values for the provided numpy array.\n",
    "\n",
    "From the `text_file` string, an array containing all characters in the text file, $A$, is generated using the function `list(string)`. This function transforms a string into a list of characters (which are then converted into a numpy array).\n",
    "\n",
    "From $A$, the set of all unique characters that appear in the US Constituion $C$ is defined as\n",
    "\n",
    "$$ C = \\{character : character \\in \\text{US Consitution}\\}.$$\n",
    "\n",
    "The `unique` function is used again to create $C$.\n",
    "\n",
    "With this operation, we find that are $69$ elements within the set $C$ - this value is saved as $n$. The elements and the count (with truncation) of the sets are printed to console below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = ['\"' '(' ')' ... 'written' 'year' 'years']\n",
      "|X| (unique words in text) =  1351 \n",
      "\n",
      "C = [' ' '\"' '(' ')' ',' '-' '.' '0' '1' '2' '3' '4' '5' '6' '7' '8' '9' ':'\n",
      " ';' 'A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q'\n",
      " 'R' 'S' 'T' 'U' 'V' 'W' 'Y' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k'\n",
      " 'l' 'm' 'n' 'o' 'p' 'q' 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n",
      "|C| (unique characters in text) = n = 69 \n",
      "\n",
      "A (total # of characters in text) = 45737\n"
     ]
    }
   ],
   "source": [
    "# Read in the US Consitution from the appropriate text file and save the\n",
    "# contents of the file as a single string.\n",
    "\n",
    "filename = \"data\\const.txt\"\n",
    "\n",
    "f = open(filename, \"r\")\n",
    "if f.mode == 'r':\n",
    "    file_text = f.read()\n",
    "\n",
    "f.close()\n",
    "\n",
    "# For punctuation, spaces either before or after (depending on the character)\n",
    "# such that the split function will be able to capture punctuation as\n",
    "# separate \"words\".\n",
    "\n",
    "file_text = file_text.replace(\".\", \" .\")\n",
    "file_text = file_text.replace(\",\", \" ,\")\n",
    "file_text = file_text.replace(\"(\", \"( \")\n",
    "file_text = file_text.replace(\")\", \" )\")\n",
    "file_text = file_text.replace(\"\\n\", \" \")\n",
    "file_text = file_text.replace(\":\", \" :\")\n",
    "file_text = file_text.replace(\";\", \" ;\")\n",
    "file_text = file_text.replace(\"\\\"\", \" \\\" \")\n",
    "\n",
    "# Convert the 'file_text' string into a series of numpy arrays:\n",
    "# W - Ordered array of words as they appear in the text file.\n",
    "# X - Array of unique words that appear in the text file.\n",
    "# A - Ordered array of characters as they appear in the text file.\n",
    "# C - Array of unique characters that appear in the text file.\n",
    "\n",
    "W = np.array(file_text.split())\n",
    "X = np.unique(W)\n",
    "\n",
    "A = np.array(list(file_text))\n",
    "C = np.unique(A)\n",
    "\n",
    "n = len(C)\n",
    "\n",
    "# Print the contents and size of X and C. Print the size of array A.\n",
    "\n",
    "print('X =', X)\n",
    "print('|X| (unique words in text) = ', len(X), \"\\n\")\n",
    "\n",
    "print('C =', C)\n",
    "print('|C| (unique characters in text) = n =', len(C), \"\\n\")\n",
    "\n",
    "print('A (total # of characters in text) =', len(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to verify if a word is valid later on, an English dictionary is also read in as saved as `en_dict`. This dictionary includes over 479k English words, as found at the following link: https://github.com/dwyl/english-words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a' 'aa' 'aaa' ... 'zyzzogeton' 'zyzzyva' 'zyzzyvas']\n"
     ]
    }
   ],
   "source": [
    "# Read in the contents of the words alpha file - which will act\n",
    "# as our english dictionary for determining whether a word is valid\n",
    "# later on.\n",
    "\n",
    "filename = \"data\\words_alpha.txt\"\n",
    "\n",
    "f = open(filename, \"r\")\n",
    "if f.mode == 'r':\n",
    "    file_text = f.read()\n",
    "\n",
    "f.close()\n",
    "\n",
    "en_dict = np.unique(np.array(file_text.split()))\n",
    "print(en_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Letter Prediction\n",
    "\n",
    "For **one-letter prediction**, the first step is to generate a Stochastic Matrix $Q$ such that we can perform single letter predictions to generate random \"words\".\n",
    "\n",
    "$Q$ is defined such that $Q_{i,j}$ defines the probability of the next character being $j$ given the current character is $i$. As $Q$ is a Stochastic Matrix, it is given that\n",
    "\n",
    "- $Q_{i,j} \\in [0,1]$.\n",
    "- The sum of each row is one.\n",
    "\n",
    "Using the definition of the Conditional Probability, the probability of the pairing of $(i, j)$ - character $i$ following by character $j$ - is defined as\n",
    "\n",
    "$$Q_{i,j} = P[J\\;|\\;I] = \\frac{P[I\\cap J]}{P[I]}$$\n",
    "\n",
    "where $I$ is the event of character $i$ appearing as the 1st character and $J$ is the event of character $j$ appearing as the 2nd character.\n",
    "\n",
    "$P[I\\cap J]$ and $P[I]$ are defined as\n",
    "\n",
    "$$P[I\\cap J] = \\frac{f_{(i,j)}}{|A|}$$\n",
    "$$P[I] = \\frac{f_{i}}{|A|}$$\n",
    "\n",
    "where $|A|$ is the total number of characters is the US Constitution and $f_x$ is the frequency of occurence of character or sequence $x$.\n",
    "\n",
    "Simplifying for $P[J\\;|\\;I]$,\n",
    "\n",
    "$$P[J\\;|\\;I] = \\frac{f_{(i,j)}}{f_{i}}.$$\n",
    "\n",
    "Thus, we see that\n",
    "\n",
    "$$Q_{i,j} = \\frac{f_{(i,j)}}{f_{i}}.$$\n",
    "\n",
    "In order to associate each character with the indices in $Q$ (or other matrices), a dictionary $D$ can be created that associates each unique character $x$ with an index $i_x$. This dictionary is defined as\n",
    "\n",
    "$$ D\\,[x] = i_x.$$\n",
    "\n",
    "For example,\n",
    "\n",
    "$$ D\\,[\\,\\text{'A'}\\,] = 19$$\n",
    "$$ D\\,[\\,\\text{'0'}\\,] = 7$$\n",
    "$$ D\\,[\\,\\text{'z'}\\,] = 68.$$\n",
    "\n",
    "A numpy array (i.e. matrix) $f$ is initialized with a size equal to $n \\times n$, with each element $f_{(i,j)} = 0$. As the character array $A$ is iterated over, each iterated element $A_x$ and succeeding element $A_{x+1}$, $1$ is added to $f_{(i, j)}$ in which $i$ and $j$ corresponds to the indices of $A_x$ and $A_{x+1}$, respectively.\n",
    "\n",
    "$f_i$ is equivalent to the sum of the $ith$ row of $f$, and thus $Q$ can be calculating using numpy's `divide` function to divie each element of $f$ by summation of its corresponding row.\n",
    "\n",
    "The contents of $Q$ (with truncation) are printed to console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q = [[1.94633191e-02 2.30335138e-04 5.75837844e-04 ... 0.00000000e+00\n",
      "  1.38201083e-03 0.00000000e+00]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.35416667e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.24528302e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary / hash of the set C - this dictionary D can\n",
    "# provide the index within our various matrices (Q, f, etc.).\n",
    "# We can do this by calling D[a], in which 'a' is our character of interest.\n",
    "\n",
    "D = {k: v for v, k in enumerate(C)}\n",
    "\n",
    "# Calculate the count of character j following i within array / matrix A.\n",
    "# For the last character x+1 = len(A), we will assume that it is followed\n",
    "# by a space.\n",
    "\n",
    "f = np.zeros((n, n))\n",
    "\n",
    "for x in range(len(A)):\n",
    "    i = D[A[x]]\n",
    "    if (x + 1) >= len(A):\n",
    "        j = D[\" \"]\n",
    "    else:\n",
    "        j = D[A[x+1]]\n",
    "\n",
    "    f[i, j] = f[i, j] + 1\n",
    "\n",
    "# Turn each value into a probability rather than a count. Numpy's divide\n",
    "# function does a true divison of the inputs elementwise, excluding instances\n",
    "# in which the sum of a row in f is equal to 0.\n",
    "Q = np.divide(f, f.sum(axis=1)[:, None],\n",
    "              out=np.zeros_like(f), where=f.sum(axis=1)[:, None] != 0)\n",
    "\n",
    "print('Q =', Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, a while loop is created to simulate the system as a Markov chain starting with an arbitrary capital letter and continues until it gets a space or any other non-alpha character (i.e. punctuations and numbers).\n",
    "\n",
    "Array `c_letters` which contains all of the capital letters that appear within the US Consitution - which, by observation, includes all letters except \"X\" and \"Z\".\n",
    "\n",
    "The resulting words are saved to an array `words`.\n",
    "\n",
    "The first step to creating a 'word' is to determine a random capital letter, using `random.choice`, and save to the variable `current_letter`. Next, the while loop is entered and iterates as long as `current_letter` is an alpha character.\n",
    "\n",
    "Inside the while loop, the loop first appends the `current_letter` to the string `word` string, which will be the output of the while loop. A new letter is determined using `np.random.choice`; `np.random.choice` is capable of choosing a random character given a probability of occurence. In this case, the probability of occurence is defined by the row $Q_{i}$ where $i$ corresponds to the index of `current_letter`.\n",
    "\n",
    "Once a `current_letter` is found that is not an alpha character, the while loop breaks and saves `word` to the array `words`.\n",
    "\n",
    "This process is wrapped by a for loop to produce $100$ random 'words'. These words are outputted to display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Array of all the capital letters that appear within the US Constitution\n",
    "c_letters = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\",\n",
    "             \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\",\n",
    "             \"U\", \"V\", \"W\", \"Y\"]\n",
    "\n",
    "words = []\n",
    "\n",
    "# Enter a for 100-iteration loop to generate 100 random 'words'.\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    # Select a random letter from the array c_letters.\n",
    "    # Iterate over the while loop until a non-alpha character is reached.\n",
    "    current_letter = random.choice(c_letters)\n",
    "    word = \"\"\n",
    "\n",
    "    while current_letter.isalpha():\n",
    "        # Add our current letter / character to our word. Select a new random letter using\n",
    "        # our probability matrix Q.\n",
    "        word = word + current_letter\n",
    "\n",
    "        current_letter = C[np.random.choice(\n",
    "            len(D), 1, p=Q[D[current_letter], :])][0]\n",
    "\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ell - Valid\n",
      "Se - Valid\n",
      "Calangen - Invalid\n",
      "In - Valid\n",
      "Ding - Valid\n",
      "Pllumest - Invalid\n",
      "Oall - Invalid\n",
      "Prurilll - Invalid\n",
      "Uny - Invalid\n",
      "Mat - Valid\n",
      "Gote - Valid\n",
      "Da - Valid\n",
      "Pr - Valid\n",
      "Ale - Valid\n",
      "Me - Valid\n",
      "Nor - Valid\n",
      "Thecanleshm - Invalid\n",
      "Adin - Valid\n",
      "Wrernthe - Invalid\n",
      "Ofonven - Invalid\n",
      "Indecesh - Invalid\n",
      "Ye - Valid\n",
      "Hotesh - Invalid\n",
      "Sthtaith - Invalid\n",
      "Distica - Invalid\n",
      "Kieshes - Invalid\n",
      "Alive - Valid\n",
      "Ar - Valid\n",
      "Aresiof - Invalid\n",
      "Un - Valid\n",
      "Re - Valid\n",
      "Appacur - Invalid\n",
      "Matarviedes - Invalid\n",
      "Vachemby - Invalid\n",
      "Gonshache - Invalid\n",
      "No - Valid\n",
      "Yer - Valid\n",
      "Angr - Invalid\n",
      "Quslll - Invalid\n",
      "Honuthoponintretag - Invalid\n",
      "Of - Valid\n",
      "Prs - Valid\n",
      "Re - Valid\n",
      "Hereshitongrang - Invalid\n",
      "Lanteshath - Invalid\n",
      "Hort - Valid\n",
      "Vomprshe - Invalid\n",
      "Horsirs - Invalid\n",
      "Of - Valid\n",
      "Jond - Invalid\n",
      "Andur - Invalid\n",
      "Noitothallererered - Invalid\n",
      "Reacudithe - Invalid\n",
      "Und - Invalid\n",
      "Dilll - Invalid\n",
      "Faler - Invalid\n",
      "Unthe - Invalid\n",
      "Yege - Invalid\n",
      "Juricr - Invalid\n",
      "Der - Valid\n",
      "Yesshivit - Invalid\n",
      "Kishe - Invalid\n",
      "Yer - Valid\n",
      "Wendgery - Invalid\n",
      "Quthrizeich - Invalid\n",
      "Nat - Valid\n",
      "Quthe - Invalid\n",
      "Viowe - Invalid\n",
      "Gere - Valid\n",
      "Jr - Valid\n",
      "Jul - Invalid\n",
      "Stomf - Invalid\n",
      "Prus - Invalid\n",
      "Qunue - Invalid\n",
      "Man - Valid\n",
      "Stiroithiof - Invalid\n",
      "Bacha - Invalid\n",
      "Prered - Invalid\n",
      "Hores - Invalid\n",
      "Ye - Valid\n",
      "Me - Valid\n",
      "No - Valid\n",
      "Votit - Invalid\n",
      "Fe - Valid\n",
      "Lesusite - Invalid\n",
      "Re - Valid\n",
      "Wid - Valid\n",
      "Vofteillanfr - Invalid\n",
      "Yes - Valid\n",
      "Lallende - Invalid\n",
      "Carchon - Invalid\n",
      "Ofrtouf - Invalid\n",
      "Vil - Valid\n",
      "Quntatare - Invalid\n",
      "Daseg - Invalid\n",
      "Fowiovio - Invalid\n",
      "Qubeay - Invalid\n",
      "Morshed - Invalid\n",
      "Lansed - Invalid\n",
      "Patexcegne - Invalid\n",
      "\n",
      "Number of valid words = 38\n",
      "Number of invalid words = 62\n"
     ]
    }
   ],
   "source": [
    "# Keep a count of all valid and invalid words when checking\n",
    "# against the english dictionary.\n",
    "valid_count = 0\n",
    "invalid_count = 0\n",
    "\n",
    "# Iterate over all the generated words and check if they exist within\n",
    "# our english dictionary array. If they exist, then output as valid\n",
    "# and add to valid counter. If not, then output as invalid and add\n",
    "# to invalid counter. Print results of counters to console.\n",
    "for word in words:\n",
    "    if word.upper() in [a.upper() for a in en_dict]:\n",
    "        print(word, '- Valid')\n",
    "        valid_count = valid_count + 1\n",
    "    else:\n",
    "        print(word, '- Invalid')\n",
    "        invalid_count = invalid_count + 1\n",
    "\n",
    "print('\\nNumber of valid words =', valid_count)\n",
    "print('Number of invalid words =', invalid_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a sample test run, below is the resulting output of the one-letter word prediction. The one-letter word prediction was able to generate $38$ valid English words out of $100$ generated \"words\" (based on the given English dictionary).\n",
    "\n",
    "```\n",
    "Ell - Valid\n",
    "Se - Valid\n",
    "Calangen - Invalid\n",
    "In - Valid\n",
    "Ding - Valid\n",
    "Pllumest - Invalid\n",
    "Oall - Invalid\n",
    "Prurilll - Invalid\n",
    "Uny - Invalid\n",
    "Mat - Valid\n",
    "Gote - Valid\n",
    "Da - Valid\n",
    "Pr - Valid\n",
    "Ale - Valid\n",
    "Me - Valid\n",
    "Nor - Valid\n",
    "Thecanleshm - Invalid\n",
    "Adin - Valid\n",
    "Wrernthe - Invalid\n",
    "Ofonven - Invalid\n",
    "Indecesh - Invalid\n",
    "Ye - Valid\n",
    "Hotesh - Invalid\n",
    "Sthtaith - Invalid\n",
    "Distica - Invalid\n",
    "Kieshes - Invalid\n",
    "Alive - Valid\n",
    "Ar - Valid\n",
    "Aresiof - Invalid\n",
    "Un - Valid\n",
    "Re - Valid\n",
    "Appacur - Invalid\n",
    "Matarviedes - Invalid\n",
    "Vachemby - Invalid\n",
    "Gonshache - Invalid\n",
    "No - Valid\n",
    "Yer - Valid\n",
    "Angr - Invalid\n",
    "Quslll - Invalid\n",
    "Honuthoponintretag - Invalid\n",
    "Of - Valid\n",
    "Prs - Valid\n",
    "Re - Valid\n",
    "Hereshitongrang - Invalid\n",
    "Lanteshath - Invalid\n",
    "Hort - Valid\n",
    "Vomprshe - Invalid\n",
    "Horsirs - Invalid\n",
    "Of - Valid\n",
    "Jond - Invalid\n",
    "Andur - Invalid\n",
    "Noitothallererered - Invalid\n",
    "Reacudithe - Invalid\n",
    "Und - Invalid\n",
    "Dilll - Invalid\n",
    "Faler - Invalid\n",
    "Unthe - Invalid\n",
    "Yege - Invalid\n",
    "Juricr - Invalid\n",
    "Der - Valid\n",
    "Yesshivit - Invalid\n",
    "Kishe - Invalid\n",
    "Yer - Valid\n",
    "Wendgery - Invalid\n",
    "Quthrizeich - Invalid\n",
    "Nat - Valid\n",
    "Quthe - Invalid\n",
    "Viowe - Invalid\n",
    "Gere - Valid\n",
    "Jr - Valid\n",
    "Jul - Invalid\n",
    "Stomf - Invalid\n",
    "Prus - Invalid\n",
    "Qunue - Invalid\n",
    "Man - Valid\n",
    "Stiroithiof - Invalid\n",
    "Bacha - Invalid\n",
    "Prered - Invalid\n",
    "Hores - Invalid\n",
    "Ye - Valid\n",
    "Me - Valid\n",
    "No - Valid\n",
    "Votit - Invalid\n",
    "Fe - Valid\n",
    "Lesusite - Invalid\n",
    "Re - Valid\n",
    "Wid - Valid\n",
    "Vofteillanfr - Invalid\n",
    "Yes - Valid\n",
    "Lallende - Invalid\n",
    "Carchon - Invalid\n",
    "Ofrtouf - Invalid\n",
    "Vil - Valid\n",
    "Quntatare - Invalid\n",
    "Daseg - Invalid\n",
    "Fowiovio - Invalid\n",
    "Qubeay - Invalid\n",
    "Morshed - Invalid\n",
    "Lansed - Invalid\n",
    "Patexcegne - Invalid\n",
    "\n",
    "Number of valid words = 38\n",
    "Number of invalid words = 62\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Letter Prediction\n",
    "\n",
    "For **two-letter prediction**, the first step is to generate a $n \\times n \\times n$ tensor, $T$, such that we can perform two letter predictions to generate random \"words\".\n",
    "\n",
    "$T$ is defined such that $T_{i,j, k}$ defines the probability of the next character being $k$ given the current character is $j$ and the previous character is $i$. $T$ has the following properties\n",
    "\n",
    "- $T_{i,j, k} \\in [0,1]$.\n",
    "- The sum of each row ($T_{i, j}$) is one.\n",
    "\n",
    "Using the definition of the Conditional Probability, the probability of the triplet of $(i, j, k)$ - character $i$ followed by character $j$ followed by character $k$ - is defined as\n",
    "\n",
    "$$T_{i,j,k} = P[K\\;|\\;(I\\cap J)] = \\frac{P[K\\cap (I\\cap J)]}{P[I \\cap J]}$$\n",
    "\n",
    "where $I$ is the event of character $i$ appearing as the 1st character, $J$ is the event of character $j$ appearing as the 2nd character, and $K$ is the event of character $k$ appearing as the 3rd character.\n",
    "\n",
    "$P[K\\cap (I\\cap J)]$ and $P[I \\cap J]$ are defined as\n",
    "\n",
    "$$P[K\\cap (I\\cap J)] = \\frac{f_{(i,j,k)}}{|A|}$$\n",
    "$$P[I\\cap J] = \\frac{f_{(i,j)}}{|A|}$$\n",
    "\n",
    "where $|A|$ is the total number of characters is the US Constitution and $f_x$ is the frequency of occurence of character or sequence $x$.\n",
    "\n",
    "Simplifying for $P[J\\;|\\;I]$,\n",
    "\n",
    "$$P[K\\;|\\;(I\\cap J)] = \\frac{f_{(i,j,k)}}{f_{(i,j)}}.$$\n",
    "\n",
    "Thus, we see that\n",
    "\n",
    "$$T_{i,j, k} = \\frac{f_{(i,j,k)}}{f_{(i,j)}}.$$\n",
    "\n",
    "A numpy array (i.e. matrix) $f$ is initialized with a size equal to $n \\times n \\times n$, with each element $f_{(i,j,k)} = 0$. As the character array $A$ is iterated over, each iterated triplet of elements ($A_x$, $A_{x+1}$, and $A_{x+2}$), $1$ is added to $f_{(i, j, k)}$ in which $i$, $j$, $k$ corresponds to the indices of $A_x$, $A_{x+1}$, and $A_{x+2}$, respectively.\n",
    "\n",
    "$f_{(i, j)}$ is equivalent to $T_{i, j, *}$, and thus $T$ can be calculating using numpy's `divide` function to divie each element of $f$ by $f_{(i,j)}$.\n",
    "\n",
    "The contents of $T$ (with truncation) are printed to console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T = [[[0.0295858  0.00591716 0.         ... 0.         0.         0.        ]\n",
      "  [1.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [1.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.5        0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.         0.         0.         ... 0.         0.07692308 0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.00226757 0.         0.00226757 ... 0.         0.00226757 0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the count of character k following i, j within array / matrix A.\n",
    "# For the last character x+1 = len(A) and the 2nd to last character x+2 = len(A),\n",
    "# we will assume that it is followed by spaces.\n",
    "f = np.zeros((n, n, n))\n",
    "\n",
    "for x in range(len(A)):\n",
    "\n",
    "    i = D[A[x]]\n",
    "\n",
    "    if (x + 1) >= len(A):\n",
    "        j = D[\" \"]  # Index of space character\n",
    "    else:\n",
    "        j = D[A[x+1]]\n",
    "\n",
    "    if (x + 2) >= len(A):\n",
    "        k = D[\" \"]  # Index of space character\n",
    "    else:\n",
    "        k = D[A[x+2]]\n",
    "\n",
    "    f[i, j, k] = f[i, j, k] + 1\n",
    "\n",
    "T = np.zeros((n, n, n))\n",
    "\n",
    "# Turn each value into a probability rather than a count. Numpy's divide\n",
    "# function does a true divison of the inputs elementwise, excluding instances\n",
    "# in which the sum of a row in f is equal to 0.\n",
    "for i in range(len(C)):\n",
    "    for j in range(len(C)):\n",
    "        if np.sum(f[i, j, :]) != 0:\n",
    "            T[i, j, :] = f[i, j, :] / np.sum(f[i, j, :])\n",
    "\n",
    "print('T =', T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to part 1, a while loop is created to simulate the system as a Markov chain starting with an arbitrary capital letter and continues until it gets a space or any other non-alpha character (i.e. punctuations and numbers).\n",
    "\n",
    "Array `c_letters` which contains all of the capital letters that appear within the US Consitution - which, by observation, includes all letters except \"X\" and \"Z\".\n",
    "\n",
    "The resulting words are saved to an array `words`.\n",
    "\n",
    "The first step to creating a 'word' is to determine a random capital letter, using `random.choice`, and save to the variable `current_letter`. Because our Markov chain is a two-letter prediction, a `previous_letter` must be defined for this initial condition. The `previous_letter` is initialized as a space.\n",
    "\n",
    "Next, the while loop is entered and iterates as long as `current_letter` is an alpha character.\n",
    "\n",
    "Inside the while loop, the loop first appends the `current_letter` to the string `word` string, which will be the output of the while loop. A new letter is determined using `np.random.choice`; `np.random.choice` is capable of choosing a random character given a probability of occurence. In this case, the probability of occurence is defined by the row $T_{(i, j)}$ where $i$ corresponds to the index of `current_letter` and $j$ corresponds to the index of `previous_letter`.\n",
    "\n",
    "The `current_letter` is overwritten as the next iteration's `previous_letter`; the `new_letter` is overwritten as the next iteration's `current_letter`.\n",
    "\n",
    "Once a `new_letter` is found that is not an alpha character, the while loop breaks and saves `word` to the array `words`.\n",
    "\n",
    "This process is wrapped by a for loop to produce $100$ random 'words'. These words are outputted to display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array of all the capital letters that appear within the US Constitution\n",
    "c_letters = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\",\n",
    "             \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\",\n",
    "             \"U\", \"V\", \"W\", \"Y\"]\n",
    "\n",
    "words = []\n",
    "\n",
    "# Enter a for 100-iteration loop to generate 100 random 'words'.\n",
    "\n",
    "for i in range(100):\n",
    "    # Select a random letter from the array c_letters and set our previous\n",
    "    # letter a space.\n",
    "\n",
    "    # Iterate over the while loop until a non-alpha character is reached.\n",
    "    current_letter = random.choice(c_letters)\n",
    "    previous_letter = \" \"\n",
    "    word = \"\"\n",
    "\n",
    "    while current_letter.isalpha():\n",
    "        # Add our current letter / character to our word. Select a new random letter using\n",
    "        # our probability matrix Q.\n",
    "        word = word + current_letter\n",
    "        new_letter = C[np.random.choice(\n",
    "            len(D), 1, p=T[D[previous_letter], D[current_letter], :])][0]\n",
    "\n",
    "        # Save the current letter to our previous letter, and\n",
    "        # set the new letter as the current letter.\n",
    "        previous_letter = current_letter\n",
    "        current_letter = new_letter\n",
    "\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yeasolatiand - Invalid\n",
      "Att - Valid\n",
      "Presies - Invalid\n",
      "Blost - Invalid\n",
      "Juding - Invalid\n",
      "Was - Valid\n",
      "To - Valid\n",
      "Secom - Invalid\n",
      "Sectice - Invalid\n",
      "Mond - Invalid\n",
      "Unitne - Invalid\n",
      "Fulate - Invalid\n",
      "Fords - Valid\n",
      "Quall - Invalid\n",
      "Hourres - Invalid\n",
      "Ame - Valid\n",
      "Grand - Valid\n",
      "Rect - Valid\n",
      "Rect - Valid\n",
      "Hugh - Valid\n",
      "Milis - Invalid\n",
      "Quannevesed - Invalid\n",
      "Lete - Valid\n",
      "Staters - Valid\n",
      "Legislavicandin - Invalid\n",
      "Objective - Valid\n",
      "In - Valid\n",
      "Vichommited - Invalid\n",
      "Reprit - Invalid\n",
      "Thin - Valid\n",
      "Yeasever - Invalid\n",
      "Aut - Invalid\n",
      "Mody - Valid\n",
      "Yeas - Valid\n",
      "Quor - Valid\n",
      "Exed - Invalid\n",
      "Quare - Valid\n",
      "Reasesesinated - Invalid\n",
      "Goves - Invalid\n",
      "Numbection - Invalid\n",
      "Buting - Invalid\n",
      "Prichompern - Invalid\n",
      "Laws - Valid\n",
      "Statersong - Invalid\n",
      "Represidecles - Invalid\n",
      "Gove - Valid\n",
      "Quartion - Invalid\n",
      "New - Valid\n",
      "Prequor - Invalid\n",
      "Legisharsoeve - Invalid\n",
      "No - Valid\n",
      "Leakent - Invalid\n",
      "Affirdiame - Invalid\n",
      "Reprommite - Invalid\n",
      "Rufulay - Invalid\n",
      "The - Valid\n",
      "They - Valid\n",
      "King - Valid\n",
      "Offich - Invalid\n",
      "Thinal - Invalid\n",
      "Ambe - Valid\n",
      "Houses - Valid\n",
      "Unites - Valid\n",
      "Feleas - Invalid\n",
      "Rebed - Valid\n",
      "Souvert - Invalid\n",
      "Facesent - Invalid\n",
      "Con - Valid\n",
      "Reprohis - Invalid\n",
      "Impointinfent - Invalid\n",
      "Bres - Invalid\n",
      "Vothe - Invalid\n",
      "Cas - Invalid\n",
      "Con - Valid\n",
      "Art - Valid\n",
      "Objectionse - Invalid\n",
      "Arts - Valid\n",
      "If - Valid\n",
      "Hamon - Invalid\n",
      "If - Valid\n",
      "Duthervites - Invalid\n",
      "This - Valid\n",
      "Fraor - Invalid\n",
      "Law - Valid\n",
      "Jand - Invalid\n",
      "Claw - Valid\n",
      "Faill - Invalid\n",
      "Fithendin - Invalid\n",
      "Impecorciesid - Invalid\n",
      "Quor - Valid\n",
      "For - Valid\n",
      "Vothempeas - Invalid\n",
      "If - Valid\n",
      "Unit - Valid\n",
      "We - Valid\n",
      "Juresemed - Invalid\n",
      "Offiedispearoplislaingrebtathe - Invalid\n",
      "Wargerfen - Invalid\n",
      "Kin - Valid\n",
      "Parthe - Invalid\n",
      "\n",
      "Number of valid words = 44\n",
      "Number of invalid words = 56\n"
     ]
    }
   ],
   "source": [
    "# Keep a count of all valid and invalid words when checking\n",
    "# against the english dictionary.\n",
    "valid_count = 0\n",
    "invalid_count = 0\n",
    "\n",
    "# Iterate over all the generated words and check if they exist within\n",
    "# our english dictionary array. If they exist, then output as valid\n",
    "# and add to valid counter. If not, then output as invalid and add\n",
    "# to invalid counter. Print results of counters to console.\n",
    "for word in words:\n",
    "    if word.upper() in [a.upper() for a in en_dict]:\n",
    "        print(word, '- Valid')\n",
    "        valid_count = valid_count + 1\n",
    "    else:\n",
    "        print(word, '- Invalid')\n",
    "        invalid_count = invalid_count + 1\n",
    "\n",
    "print('\\nNumber of valid words =', valid_count)\n",
    "print('Number of invalid words =', invalid_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a sample test run, below is the resulting output of the two-letter word prediction. The two-letter word prediction was able to generate $44$ valid English words out of $100$ generated \"words\" (based on the given English dictionary).\n",
    "\n",
    "```\n",
    "Yeasolatiand - Invalid\n",
    "Att - Valid\n",
    "Presies - Invalid\n",
    "Blost - Invalid\n",
    "Juding - Invalid\n",
    "Was - Valid\n",
    "To - Valid\n",
    "Secom - Invalid\n",
    "Sectice - Invalid\n",
    "Mond - Invalid\n",
    "Unitne - Invalid\n",
    "Fulate - Invalid\n",
    "Fords - Valid\n",
    "Quall - Invalid\n",
    "Hourres - Invalid\n",
    "Ame - Valid\n",
    "Grand - Valid\n",
    "Rect - Valid\n",
    "Rect - Valid\n",
    "Hugh - Valid\n",
    "Milis - Invalid\n",
    "Quannevesed - Invalid\n",
    "Lete - Valid\n",
    "Staters - Valid\n",
    "Legislavicandin - Invalid\n",
    "Objective - Valid\n",
    "In - Valid\n",
    "Vichommited - Invalid\n",
    "Reprit - Invalid\n",
    "Thin - Valid\n",
    "Yeasever - Invalid\n",
    "Aut - Invalid\n",
    "Mody - Valid\n",
    "Yeas - Valid\n",
    "Quor - Valid\n",
    "Exed - Invalid\n",
    "Quare - Valid\n",
    "Reasesesinated - Invalid\n",
    "Goves - Invalid\n",
    "Numbection - Invalid\n",
    "Buting - Invalid\n",
    "Prichompern - Invalid\n",
    "Laws - Valid\n",
    "Statersong - Invalid\n",
    "Represidecles - Invalid\n",
    "Gove - Valid\n",
    "Quartion - Invalid\n",
    "New - Valid\n",
    "Prequor - Invalid\n",
    "Legisharsoeve - Invalid\n",
    "No - Valid\n",
    "Leakent - Invalid\n",
    "Affirdiame - Invalid\n",
    "Reprommite - Invalid\n",
    "Rufulay - Invalid\n",
    "The - Valid\n",
    "They - Valid\n",
    "King - Valid\n",
    "Offich - Invalid\n",
    "Thinal - Invalid\n",
    "Ambe - Valid\n",
    "Houses - Valid\n",
    "Unites - Valid\n",
    "Feleas - Invalid\n",
    "Rebed - Valid\n",
    "Souvert - Invalid\n",
    "Facesent - Invalid\n",
    "Con - Valid\n",
    "Reprohis - Invalid\n",
    "Impointinfent - Invalid\n",
    "Bres - Invalid\n",
    "Vothe - Invalid\n",
    "Cas - Invalid\n",
    "Con - Valid\n",
    "Art - Valid\n",
    "Objectionse - Invalid\n",
    "Arts - Valid\n",
    "If - Valid\n",
    "Hamon - Invalid\n",
    "If - Valid\n",
    "Duthervites - Invalid\n",
    "This - Valid\n",
    "Fraor - Invalid\n",
    "Law - Valid\n",
    "Jand - Invalid\n",
    "Claw - Valid\n",
    "Faill - Invalid\n",
    "Fithendin - Invalid\n",
    "Impecorciesid - Invalid\n",
    "Quor - Valid\n",
    "For - Valid\n",
    "Vothempeas - Invalid\n",
    "If - Valid\n",
    "Unit - Valid\n",
    "We - Valid\n",
    "Juresemed - Invalid\n",
    "Offiedispearoplislaingrebtathe - Invalid\n",
    "Wargerfen - Invalid\n",
    "Kin - Valid\n",
    "Parthe - Invalid\n",
    "\n",
    "Number of valid words = 44\n",
    "Number of invalid words = 56\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Prediction\n",
    "\n",
    "For **word prediction**, an assumption is made to use a one-word approach - similar to part 1 of this solution. The first step is to generate a Stochastic Matrix $Y$ such that single word predictions can be made to generate random sentences.\n",
    "\n",
    "$Y$ is defined such that $Y_{i,j}$ defines the probability of the next word being $j$ given the current word is $i$. As $Y$ is a Stochastic Matrix, it is given that\n",
    "\n",
    "- $Y_{i,j} \\in [0,1]$.\n",
    "- The sum of each row is one.\n",
    "\n",
    "Using the definition of the Conditional Probability, the probability of the pairing of $(i, j)$ - word $i$ following by word $j$ - is defined as\n",
    "\n",
    "$$Y_{i,j} = P[J\\;|\\;I] = \\frac{P[I\\cap J]}{P[I]}$$\n",
    "\n",
    "where $I$ is the event of word $i$ appearing as the 1st word and $J$ is the event of word $j$ appearing as the 2nd word.\n",
    "\n",
    "$P[I\\cap J]$ and $P[I]$ are defined as\n",
    "\n",
    "$$P[I\\cap J] = \\frac{f_{(i,j)}}{|W|}$$\n",
    "$$P[I] = \\frac{f_{i}}{|W|}$$\n",
    "\n",
    "where $|W|$ is the total number of words is the US Constitution and $f_x$ is the frequency of occurrence of a word or words $x$.\n",
    "\n",
    "Simplifying for $P[J\\;|\\;I]$,\n",
    "\n",
    "$$P[J\\;|\\;I] = \\frac{f_{(i,j)}}{f_{i}}.$$\n",
    "\n",
    "Thus, we see that\n",
    "\n",
    "$$Y_{i,j} = \\frac{f_{(i,j)}}{f_{i}}.$$\n",
    "\n",
    "In order to associate each character with the indices in $F$ (or other matrices), a dictionary $D$ can be created that associates each unique word $x$ with an index $i_x$. This dictionary is defined as\n",
    "\n",
    "$$ D\\,[x] = i_x.$$\n",
    "\n",
    "A numpy array (i.e. matrix) $f$ is initialized with a size equal to $m \\times m$, with each element $f_{(i,j)} = 0$, where $m$ is equal to the number of unique words in the US Constitution. As the word array $W$ is iterated over, each iterated element $W_x$ and succeeding element $W_{x+1}$, $1$ is added to $f_{(i, j)}$ in which $i$ and $j$ corresponds to the indices of $W_x$ and $W_{x+1}$, respectively.\n",
    "\n",
    "$f_i$ is equivalent to the sum of the $ith$ row of $f$, and thus $Y$ can be calculating using numpy's `divide` function to divie each element of $f$ by summation of its corresponding row.\n",
    "\n",
    "The contents of $Y$ (with truncation) are printed to console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y = [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary / hash of the set X - this dictionary D can\n",
    "# provide the index within our matrix Y. We can do this by calling\n",
    "# D[word], in which 'word' is our word of interest.\n",
    "\n",
    "D = {k: v for v, k in enumerate(X)}\n",
    "\n",
    "# Calculate the count of character j following i within array / matrix J.\n",
    "# Skip the last word as it should be a period.\n",
    "m = len(X)\n",
    "f = np.zeros((m, m))\n",
    "\n",
    "for x in range(len(W) - 1):\n",
    "    i = D[W[x]]\n",
    "    j = D[W[x+1]]\n",
    "\n",
    "    f[i, j] = f[i, j] + 1\n",
    "\n",
    "# Turn each value into a probability rather than a count. Numpy's divide\n",
    "# function does a true divison of the inputs elementwise, excluding instances\n",
    "# in which the sum of a row in f is equal to 0.\n",
    "Y = np.divide(f, f.sum(axis=1)[:, None],\n",
    "              out=np.zeros_like(f),\n",
    "              where=f.sum(axis=1)[:, None] != 0)\n",
    "\n",
    "print('Y =', Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to part 1, a while loop is created to simulate the system as a Markov chain starting with an arbitrary word and continues until it reaches a period - thus ending the sentence. The resulting sentence is saved to a string sentence.\n",
    "\n",
    "The first step to creating a 'word' is to determine a word, using `random.choice`, and save to the variable `current_word`. Next, the while loop is entered and iterates as long as `current_word` is not a period.\n",
    "\n",
    "Inside the while loop, the loop first appends the `current_word` to the string `sentence` string, which will be the output of the while loop. A new letter is determined using `np.random.choice`; `np.random.choice` is capable of choosing a random word given a probability of occurence. In this case, the probability of occurence is defined by the row $Y_{i}$ where $i$ corresponds to the index of `current_word`.\n",
    "\n",
    "This `new_word` is appended onto the sentence with a space after the previous word. There are few special conditions in which a space is not added (for punctuations).\n",
    "\n",
    "Once a `new_word` is found that is a period, the while loop breaks. The resulting sentence is outputted to display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longer Term of the Laws of the President shall originate in the same, they shall not exceeding ten, or property be made within that Office of citizens twenty-one years of the House, both Houses shall be vested in Proportion to make any other State and Vice-President of Choosing Senators and other Place than once.\n"
     ]
    }
   ],
   "source": [
    "# Select a random word from the array X (which contains all unique words\n",
    "# in the US consitution.) Append this word onto our sentence and enter\n",
    "# the while loop. Iterate over the while loop until a period is reached.\n",
    "current_word = random.choice(X)\n",
    "sentence = current_word\n",
    "\n",
    "while current_word != \".\":\n",
    "    # Select a random word using our Probability matrix Y as generated before.\n",
    "\n",
    "    current_word = X[np.random.choice(len(D), 1, p=Y[D[current_word], :])][0]\n",
    "\n",
    "    # If the current word is a punctuation, do not add a space before the 'word'.\n",
    "    # Else, add a space to the end of our current sentence before adding the word.\n",
    "\n",
    "    if current_word == \".\" or current_word == \",\" or current_word == \")\" or current_word == \":\":\n",
    "        sentence = sentence + current_word\n",
    "    else:\n",
    "        sentence = sentence + \" \" + current_word\n",
    "\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a sample test run, the following sentence was generated:\n",
    "\n",
    "```\n",
    "longer Term of the Laws of the President shall originate in the same, they shall not exceeding ten, or property be made within that Office of citizens twenty-one years of the House, both Houses shall be vested in Proportion to make any other State and Vice-President of Choosing Senators and other Place than once.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
