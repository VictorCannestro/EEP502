{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T16:05:23.746666Z",
     "start_time": "2019-09-24T16:05:23.741461Z"
    },
    "colab_type": "text",
    "id": "6XR6p8emzIE0"
   },
   "source": [
    "## EE 502 P: Analytical Methods for Electrical Engineering\n",
    "    \n",
    "# Homework 10: Review\n",
    "## Due 15 December, 2019 at 11:59 PM\n",
    "### <span style=\"color: red\">Miller Sakmar (msakmar)</span>\n",
    "\n",
    "Copyright &copy; 2019, University of Washington"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import urllib.request \n",
    "import numpy as np\n",
    "import collections\n",
    "import fractions\n",
    "import string\n",
    "np.random.seed(19680801) #Fixing the random seed for reproducability\n",
    "ConstitutionURL = \"https://www.usconstitution.net/const.txt\"\n",
    "#Source of ScrabbleDictionary: https://drive.google.com/file/d/1oGDf1wjWp5RF_X9C7HoedhIWMh5uJs8s/view\n",
    "FullScrabbleFilePath = \"./Collins_Scrabble_Words_2019.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hallucinating the Constitution\n",
    "\n",
    "Consider the constitution of the United States:\n",
    "\n",
    "> https://www.usconstitution.net/const.txt .\n",
    "\n",
    "This document contains upper- and lower-case letters, numbers, and basic punctuation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction:\n",
    "In this paper, we will be utilizing Markov models to perform one-letter, two-letter, and one-word prediction based off of a dictionary created from the Constitution of the United States.  Markov models follow the Markov property, in that future states, in this case letters or words, only depend on the current state and not the previous states.  The mathematical notation for a process that is Markov is as follows:\n",
    "$$\n",
    "P[X_{n+1} = j \\;|\\; X_n = i,X_{n-1} = i_{n-1}, ..., X_0 = i_0 ] = P[X_{n+1} = j \\;|\\; X_n = i] = P_{i,j}\n",
    "$$\n",
    "where $X$ is a random variable and, in our case, represents a letter or a word.  More specifically, $P_{i,j}$ is the probability that the next character is $j$ given that the current character is $i$.\n",
    "\n",
    "Both the one-letter and one-word prediction models can be described as 1st order Markov processes.  The two-letter prediction model, however, is a 2nd order Markov process because the next state relies on the current state *and* the previous state\n",
    "$$\n",
    "P[X_{n+1} = k \\;|\\; X_n = j,X_{n-1} = i, X_{n-2} = i_{n-2}, ..., X_0 = i_0 ] = P[X_{n+1} = k \\;|\\; X_n = j,X_{n-1} = i] = P_{i,j,k}.\n",
    "$$\n",
    "\n",
    "We can then organize these probabilities together into a transition probability matrix P, where\n",
    "$$\n",
    "\\displaystyle\n",
    "P = \n",
    "\\begin{pmatrix}\n",
    "    P_{0,0} & P_{0,1} & \\dots & P_{0,j} & \\dots & P_{0,j-1} & P_{0,n-1}\\\\\n",
    "    P_{1,0} & P_{1,1} & \\dots & P_{1,j} & \\dots & P_{1,j-1} & P_{1,n-1} \\\\\n",
    "    \\vdots  & \\vdots  & \\dots & \\vdots  & \\dots & \\vdots  & \\vdots  \\\\\n",
    "    P_{i,0} & P_{i,1} & \\dots & P_{i,j} & \\dots & P_{i,j-1} & P_{i,n-1} \\\\\n",
    "    \\vdots  & \\vdots  & \\dots & \\vdots  & \\dots & \\vdots  & \\vdots  \\\\\n",
    "    P_{n-1,0} & P_{n-1,1} & \\dots & P_{n-1,j} & \\dots & P_{n-1,j-1} & P_{n-1,n-1}\n",
    "\\end{pmatrix},\n",
    "$$\n",
    "\n",
    "and each row either sums to 0 or 1.  If a row sums to 0, it means that the first character or word in a character/word-pair does not exist in the dictionary or it is the last pair read into the dictionary.  We will cover how these situations were handled later in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Small Example:\n",
    "\n",
    "For example, the transition probability matrix for the first few words of the Constitution, **\"We the People of the United States, \"** would be constructed by following the steps below:\n",
    "\n",
    "1. Find all of the unique characters in the string, \"We the People of the United States, \".  This resulted in the array: **[W, e, ' ', t, h, P, o, p, l, f, U, n, i, d, S, a, s,',']**.\n",
    "\n",
    "     1. Note how spaces, **' '**, punctuations, '**,**', and capital *and* lower-case characters are included in this array.\n",
    "     \n",
    "     \n",
    "2. Count the total number of occurences for each character and character-pair and then divided each unique character-pair by the total number of character-pairs found.  For example, all of the character pairs with beginning with the character 'e' are: **['e ': 4, 'eo': 1, 'ed': 1, 'es': 1]**, which add to $7$ total occurences of character-pairs starting with the letter 'e'.  The probability vector of character-pairs beginning with 'e' is then \n",
    "\n",
    "| Starting/Ending Letter | W | e   | ' ' | t   | h   | P   | o   | p   | l | f   | U   | n | i | d   | S   | a   | s   | , |\n",
    "|------------------------|---|-----|-----|-----|-----|-----|-----|-----|---|-----|-----|---|---|-----|-----|-----|-----|---|\n",
    "| e                      | 0 | 0   | $\\frac{4}{7}$ | 0   | 0   | 0   | $\\frac{1}{7}$ | 0   | 0 | 0   | 0   | 0 | 0 | $\\frac{1}{7}$ | 0   | 0   | $\\frac{1}{7}$ | 0 |\n",
    "\n",
    "\n",
    "3. Combine each probability vector together into a matrix (printed as a table for easier viewing)\n",
    "\n",
    "| Starting/Ending Letter | W | e   | ' ' | t   | h   | P   | o   | p   | l | f   | U   | n | i | d   | S   | a   | s   | , |\n",
    "|------------------------|---|-----|-----|-----|-----|-----|-----|-----|---|-----|-----|---|---|-----|-----|-----|-----|---|\n",
    "| W                      | 0 | 1   | 0   | 0   | 0   | 0   | 0   | 0   | 0 | 0   | 0   | 0 | 0 | 0   | 0   | 0   | 0   | 0 |\n",
    "| e                      | 0 | 0   | $\\frac{4}{7}$ | 0   | 0   | 0   | $\\frac{1}{7}$ | 0   | 0 | 0   | 0   | 0 | 0 | $\\frac{1}{7}$ | 0   | 0   | $\\frac{1}{7}$ | 0 |\n",
    "| ' '                    | 0 | 0   | $\\frac{1}{7}$ | $\\frac{2}{7}$ | 0   | $\\frac{1}{7}$ | $\\frac{1}{7}$ | 0   | 0 | 0   | $\\frac{1}{7}$ | 0 | 0 | 0   | $\\frac{1}{7}$ | 0   | 0   | 0 |\n",
    "| t                      | 0 | $\\frac{2}{5}$ | 0   | 0   | $\\frac{2}{5}$ | 0   | 0   | 0   | 0 | 0   | 0   | 0 | 0 | 0   | 0   | $\\frac{1}{5}$ | 0   | 0 |\n",
    "| h                      | 0 | 1   | 0   | 0   | 0   | 0   | 0   | 0   | 0 | 0   | 0   | 0 | 0 | 0   | 0   | 0   | 0   | 0 |\n",
    "| P                      | 0 | 1   | 0   | 0   | 0   | 0   | 0   | 0   | 0 | 0   | 0   | 0 | 0 | 0   | 0   | 0   | 0   | 0 |\n",
    "| o                      | 0 | 0   | 0   | 0   | 0   | 0   | 0   | $\\frac{1}{2}$ | 0 | $\\frac{1}{2}$ | 0   | 0 | 0 | 0   | 0   | 0   | 0   | 0 |\n",
    "| p                      | 0 | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 1 | 0   | 0   | 0 | 0 | 0   | 0   | 0   | 0   | 0 |\n",
    "| l                      | 0 | 1   | 0   | 0   | 0   | 0   | 0   | 0   | 0 | 0   | 0   | 0 | 0 | 0   | 0   | 0   | 0   | 0 |\n",
    "| f                      | 0 | 0   | 1   | 0   | 0   | 0   | 0   | 0   | 0 | 0   | 0   | 0 | 0 | 0   | 0   | 0   | 0   | 0 |\n",
    "| U                      | 0 | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0 | 0   | 0   | 1 | 0 | 0   | 0   | 0   | 0   | 0 |\n",
    "| n                      | 0 | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0 | 0   | 0   | 0 | 1 | 0   | 0   | 0   | 0   | 0 |\n",
    "| i                      | 0 | 0   | 0   | 1   | 0   | 0   | 0   | 0   | 0 | 0   | 0   | 0 | 0 | 0   | 0   | 0   | 0   | 0 |\n",
    "| d                      | 0 | 0   | 1   | 0   | 0   | 0   | 0   | 0   | 0 | 0   | 0   | 0 | 0 | 0   | 0   | 0   | 0   | 0 |\n",
    "| S                      | 0 | 0   | 0   | 1   | 0   | 0   | 0   | 0   | 0 | 0   | 0   | 0 | 0 | 0   | 0   | 0   | 0   | 0 |\n",
    "| a                      | 0 | 0   | 0   | 1   | 0   | 0   | 0   | 0   | 0 | 0   | 0   | 0 | 0 | 0   | 0   | 0   | 0   | 0 |\n",
    "| s                      | 0 | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0 | 0   | 0   | 0 | 0 | 0   | 0   | 0   | 0   | 1 |\n",
    "| ,                      | 0 | 0   | 1   | 0   | 0   | 0   | 0   | 0   | 0 | 0   | 0   | 0 | 0 | 0   | 0   | 0   | 0   | 0 |\n",
    "    \n",
    "   1. Note how the character-pair, 'We', and the first character, 'W', only occur once in the string, \"We the People of the United States, \".  Therefore if the first character of a character-pair is 'W', there is a 100% probability of transitioning to the letter 'e'.\n",
    "   2. Also note that to move along the transition probability matrix, we start with a letter, match it to a letter along the left-side of the matrix (the rows), then move across the columns to find the desired character-pair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Up the Small Example, Above:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Find all of the unique characters in the string, \"We the People of the United States, \"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below cell, we define a function, UniqueCharacterSetCounter, that utilizes the collection regular expression and collections libraries.  This function splits our string into overlapping pieces of smaller strings by using a regular expression.  We then pass these smaller strings into a counter collection, which creates a dictionary from these smaller strings and counts the occurence for each repetitive string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UniqueCharacterSetCounter(_FileString,_CharacterSetNumber):\n",
    "    \"\"\"Count the number of occurences for each character in a string, filestring\"\"\" \n",
    "    matches = re.finditer(r'(?=(.{' +str(_CharacterSetNumber) + '}))',_FileString)\n",
    "    _Counter = collections.Counter([match.group(1) for match in matches])\n",
    "    return _Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our function, we can pass our function our small example string, \"We the People of the United States, \".  The function outputs a counter dictionary that can be converted to a list to print out our desired unique character array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Unique Characters:  ['W', 'e', ' ', 't', 'h', 'P', 'o', 'p', 'l', 'f', 'U', 'n', 'i', 'd', 'S', 'a', 's', ',']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. Find all of the unique characters in the string, \"We the People of the United States, \".\n",
    "ExampleString = \"We the People of the United States, \"\n",
    "ExampleOneCharacterCounter = UniqueCharacterSetCounter(ExampleString,1)\n",
    "ExampleOneCharacterList = list(ExampleOneCharacterCounter.items())\n",
    "ExampleOneCharacterListCharacters = [index[0] for index in ExampleOneCharacterList]\n",
    "print(\"List of Unique Characters: \",ExampleOneCharacterListCharacters)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Count the total number of occurences for each character and character-pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we used a counter to track our unique characters and character-pairs, we can print out the whole counter dictionary to know how many each character and character-pairs occur in our small example string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Occurences for Each Unique Character:  [('W', 1), ('e', 7), (' ', 7), ('t', 5), ('h', 2), ('P', 1), ('o', 2), ('p', 1), ('l', 1), ('f', 1), ('U', 1), ('n', 1), ('i', 1), ('d', 1), ('S', 1), ('a', 1), ('s', 1), (',', 1)]\n",
      "\n",
      "Total Occurences for Each Unique Character-Pair:  [('We', 1), ('e ', 4), (' t', 2), ('th', 2), ('he', 2), (' P', 1), ('Pe', 1), ('eo', 1), ('op', 1), ('pl', 1), ('le', 1), (' o', 1), ('of', 1), ('f ', 1), (' U', 1), ('Un', 1), ('ni', 1), ('it', 1), ('te', 2), ('ed', 1), ('d ', 1), (' S', 1), ('St', 1), ('ta', 1), ('at', 1), ('es', 1), ('s,', 1), (', ', 1)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2. Count the total number of occurences for each character and character-pair\n",
    "ExampleTwoCharactersCounter = UniqueCharacterSetCounter(ExampleString,2)\n",
    "print(\"Total Occurences for Each Unique Character: \",list(ExampleOneCharacterCounter.items()))\n",
    "print(\"\")\n",
    "print(\"Total Occurences for Each Unique Character-Pair: \",list(ExampleTwoCharactersCounter.items()))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our small walk-through, above, we showed the occurence and probability for character-pairs when the first letter is 'e'.  To accomplish this in code, we utilize the function below, MatchingCharacterSets, which uses list comprehension to loop through each key, or character-pair, in the ExampleOneCharacterCounter dictionary and will only add pairs that begin with 'e' to a separate dictionary.  The function then prints the full dictionary, the matching sub-dictionary with 'e', and the total sum of occurences for character-pairs with 'e', which is $7$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MatchingCharacterSets(_InputCounter,_SearchKey):\n",
    "    \n",
    "    print(\"The original dictionary is : \" + str(list(_InputCounter.keys()))) \n",
    "    print(\"\")\n",
    "    \n",
    "    # Key starts with search_key in dictionary \n",
    "    _MatchingCharacterKeys = {key:val for key, val in _InputCounter.items() if (key.startswith(_SearchKey))}\n",
    "\n",
    "    # printing result  \n",
    "    print(\"The matching dictionary is: \" + str(list(_MatchingCharacterKeys)))\n",
    "    print(\"\")\n",
    "    \n",
    "    #Get total count of two character pairs that start with search_key\n",
    "    print(\"Sum of character sets that start with {}: {}\".format(_SearchKey,np.sum(list(_MatchingCharacterKeys.values()))))\n",
    "    print(\"\")\n",
    "    return _MatchingCharacterKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For example, the character-pairs starting with the letter 'e': \n",
      "The original dictionary is : ['We', 'e ', ' t', 'th', 'he', ' P', 'Pe', 'eo', 'op', 'pl', 'le', ' o', 'of', 'f ', ' U', 'Un', 'ni', 'it', 'te', 'ed', 'd ', ' S', 'St', 'ta', 'at', 'es', 's,', ', ']\n",
      "\n",
      "The matching dictionary is: ['e ', 'eo', 'ed', 'es']\n",
      "\n",
      "Sum of character sets that start with e: 7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"For example, the character-pairs starting with the letter 'e': \")\n",
    "ExampleMatchingCounter = MatchingCharacterSets(ExampleTwoCharactersCounter,'e')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate the individual probabilities for every character-pair that starts with 'e', we write another function, CreateCharacterPVector, that returns the characters' calculated transition probability vector.  This function accomplishs its task by simply using for-loops through the input CharacterList, our matching character-pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given a CharacterList, return a list of capital letters and a Pvector for those capital letters\n",
    "#Create a Pvector of available Capital letters in the Pmatrix\n",
    "def CreateCharacterPVector(_CharacterList,_LettersOnly=True,_CapitalLettersOnly=True):\n",
    "    \"\"\"Given a CharacterList, return a list of characters and a transition probability vector, Pvector, for those capital letters\"\"\"\n",
    "    _Characters = []\n",
    "    OccurenceSum = 0\n",
    "    _PVector = []\n",
    "    \n",
    "    for index in _CharacterList:\n",
    "        if(_CapitalLettersOnly):\n",
    "            if(index[0].isupper()):\n",
    "                _Characters.append(index[0])\n",
    "                OccurenceSum += index[1]\n",
    "                _PVector.append(index[1])\n",
    "        elif(_LettersOnly):\n",
    "            if(index[0].isalpha()):\n",
    "                _Characters.append(index[0])\n",
    "                OccurenceSum += index[1]\n",
    "                _PVector.append(index[1])\n",
    "        else:\n",
    "            _Characters.append(index[0])\n",
    "            OccurenceSum += index[1]\n",
    "            _PVector.append(index[1])\n",
    "    for index in range(len(_Characters)):\n",
    "        _PVector[index] = _PVector[index]/OccurenceSum\n",
    "    return _Characters, _PVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character array :  ['e ', 'eo', 'ed', 'es']\n",
      "\n",
      "Transition Probability Vector:  [0.5714285714285714, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285]\n"
     ]
    }
   ],
   "source": [
    "ExampleMatchingList = list(ExampleMatchingCounter.items())\n",
    "Characters, CharactersPVector = CreateCharacterPVector(ExampleMatchingList,_LettersOnly=False,_CapitalLettersOnly=False)\n",
    "print(\"Character array : \",Characters)\n",
    "print(\"\")\n",
    "print(\"Transition Probability Vector: \",CharactersPVector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the above probability vector that if the current character is 'e', the probability of the next character being a space, ' ', is ~57% $\\displaystyle (\\frac{4}{7})$, whereas the probability of the next character being an 'o', 'd,', or 's' is only ~14% $\\displaystyle (\\frac{1}{7})$ for each character.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Combine each probability vector together into a matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we understand how a probability vector is constructed, we can carry the same principles over to making a transition probability matrix.  To accomplish this new task, we write another function, Create2DPMatrix.  This matrix uses two for-loops to iterate through a $n \\times n$ transition probability matrix, where $n$ is the total number of unique characters in our input dictionary.\n",
    "\n",
    "The function fills each $P_{i,j}$ with the appropriate probability of the character $j$ occuring after the character $i$.\n",
    "\n",
    "We run into one edge-case this way, in that the last character in our input string does not have another character to pair to.  We handle this by manually pairing the last character to another character in our dictionary.  We could also choose to ignore it, but by pairing it with another character, we allow our simulated Markov chain to continue instead of ending when it hits the last character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a 2DPMatrix\n",
    "#Pair the last character to space to complete the pair and make the probability of the laster character pair equal to 1\n",
    "\n",
    "def Create2DPMatrix(_OneCharacterList,_OneCharacterCounter,_TwoCharactersCounter,_InputFileString):\n",
    "    \"\"\"Given a CharacterList, OneCharacterList, of single unique characters, and two counters of unique single-characters and unique characters-pairs, OneCharacterCounter and TwoCharacterCounter,\"\"\"\n",
    "    \"\"\"return a transition probability matrix, _P.\"\"\"\n",
    "    n = len(_OneCharacterList)\n",
    "    _P = np.zeros((n,n))\n",
    "    _P[CharacterIndexSearch(_OneCharacterList,LastCharacterOfFileString(_InputFileString,1)),CharacterIndexSearch(_OneCharacterList, ' ')] = 1/_OneCharacterCounter.get(LastCharacterOfFileString(_InputFileString,1))\n",
    "    for row in range(np.shape(_P)[0]):\n",
    "        for col in range(np.shape(_P)[1]):\n",
    "            #print(\"_OneCharacterList[row][0]: \",_OneCharacterList[row][0])\n",
    "            #print(\"_OneCharacterList[col][0]: \",_OneCharacterList[col][0])\n",
    "            if(_TwoCharactersCounter.get(_OneCharacterList[row][0] + _OneCharacterList[col][0]) != None):\n",
    "                #print(sm.Rational(_TwoCharactersCounter.get(_OneCharacterList[row][0] + _OneCharacterList[col][0]),_OneCharacterList[row][1]))\n",
    "                _P[row,col] += _TwoCharactersCounter.get(_OneCharacterList[row][0] + _OneCharacterList[col][0])/_OneCharacterList[row][1]\n",
    "    return _P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have made the transitiona probability matrix, we need to verify that every row either sums to 0 or 1. This is our sanity check for if we properly constructed our matrix.  A probability of greater or less than 1 for each row is not possible, unless it is the last character in our input string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VerifyValid2DPMatrix(_P):\n",
    "    \"\"\"Given a Markov probability matrix, Pmatrix, verify that all of the rows sum to either 0 or 1.\"\"\"\n",
    "    _TrackingBool = True\n",
    "    for index in np.arange(_P.shape[0]):\n",
    "        #if((np.round(np.sum(Pmatrix[index,:]),10)) == 0):\n",
    "        #        continue\n",
    "        if( (np.round(np.sum(_P[index,:]),10)) != 1):\n",
    "            print(\"Sum of row, {} does not equal 1!\".format(index))\n",
    "            print(_P[index,:])\n",
    "            _TrackingBool = False\n",
    "    return _TrackingBool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to handle the last character in our input string, we first have to be able to know what it is.  Thus, we make the function LastCharacterOfFileString, which simply uses slicing of the input string.  We mainly created this function to help clarify the Create2DPMatrix function's code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LastCharacterOfFileString(_InputFileString,_NumOfCharacters):\n",
    "    \"\"\"Given a string of characters, return the NumOfCharacters .\"\"\" \n",
    "    return _InputFileString[-_NumOfCharacters:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have noticed by now, our probability vectors, and therefore our probability matrix, do/does not contain explicitly-matched characters for each row and column.  Therefore, we need a function, CharacterIndexSearch, that translates a character to a matrix index.\n",
    "\n",
    "This enables us to find where the last character in the input string lies in the character list, which then maps to what row to use in the probability matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CharacterIndexSearch(_CharacterList,_CharacterSearch):\n",
    "    \"\"\"Given a _CharacterList and a _CharacterSearch character to search for in the _CharacterList.\"\"\"\n",
    "    \"\"\"Return either the index for the found character in the _CharacterList or return -1 if the _CharacterSearch could not be found.\"\"\"\n",
    "    counter = 0\n",
    "    for index in _CharacterList:\n",
    "        _CharacterSearchIndex = -1\n",
    "        if index[0] == _CharacterSearch:\n",
    "            _CharacterSearchIndex = counter\n",
    "            break\n",
    "        counter = counter + 1\n",
    "    return _CharacterSearchIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The resulting transition probability matrix: \n",
      "[[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 4/7 0 0 0 1/7 0 0 0 0 0 0 1/7 0 0 1/7 0]\n",
      " [0 0 1/7 2/7 0 1/7 1/7 0 0 0 1/7 0 0 0 1/7 0 0 0]\n",
      " [0 2/5 0 0 2/5 0 0 0 0 0 0 0 0 0 0 1/5 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1/2 0 1/2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#3. Combine each probability vector together into a matrix\n",
    "ExamplePMatrix = Create2DPMatrix(ExampleOneCharacterList,ExampleOneCharacterCounter,ExampleTwoCharactersCounter,ExampleString)\n",
    "\n",
    "#We use the fractions library to convert our floats to fractions\n",
    "np.set_printoptions(formatter={'all':lambda ExamplePMatrix: str(fractions.Fraction(ExamplePMatrix).limit_denominator())})\n",
    "print(\"The resulting transition probability matrix: \")\n",
    "print(ExamplePMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Creating random words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our transition probability matrix, we can actually simulate the markov process by picking a random first **capital** letter and following the matrix.  To do this, we make another function, GenerateWords, which takes a first letter, a character list, a number for how many random words to craft, and a transition probability matrix, P."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateWords(_FirstLetter,_CharacterList,_NumberOfWords,_P):\n",
    "    \"\"\"Given a letter, _FirstLetter, a list of characters, _CharacterList, the number of words to create, _NumberOfWords, and a transition probability matrix, P,\"\"\"\n",
    "    \"\"\"return _NumberOfWords random words.\"\"\"\n",
    "    CharacterListLetters = [index[0] for index in _CharacterList]\n",
    "    LoopLimit = 0\n",
    "    WordArray = []\n",
    "    WordSet = {}\n",
    "    #generate unique words until looplimit\n",
    "    while ( (len(WordSet) != _NumberOfWords) and (LoopLimit < 1000) ):\n",
    "        CurrentCharacter = _FirstLetter\n",
    "        CurrentCharacterIndex = CharacterIndexSearch(_CharacterList, _FirstLetter)\n",
    "        Word = CurrentCharacter\n",
    "        while (CurrentCharacter != \" \"): \n",
    "            CurrentCharacter = list(np.random.choice(CharacterListLetters, 1, p=(np.array(_P[CurrentCharacterIndex,:]).astype(np.float64)).flatten()))[0]\n",
    "            CurrentCharacterIndex = CharacterIndexSearch(_CharacterList, CurrentCharacter)\n",
    "\n",
    "            Word = Word + CurrentCharacter\n",
    "        #Condition the word so that it can be a *real* word without punctuation\n",
    "        Word = (Word.translate(str.maketrans('', '', string.punctuation))).replace(' ','')\n",
    "        WordArray.append(Word)\n",
    "        WordSet = set(WordArray)\n",
    "        LoopLimit = LoopLimit + 1\n",
    "    return WordSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But before we can start making random words, we first have to tackle how to choose our first capital letter.  Luckily, we have a function that can calculate a probability vector of a character list, CreateCharacterPVector!  We can then feed this transition probability vector into the numpy random choice library, which can take a non-uniform probability array, our probability vector, and a same-sized array to choose from, our available capital letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arbitrary Capital Letter Selected:  U\n"
     ]
    }
   ],
   "source": [
    "#Selecting an arbitrary first capital letter\n",
    "AvailableCapitalLetters, AvailableCapitalLettersPVector = CreateCharacterPVector(ExampleOneCharacterList, _CapitalLettersOnly=True)\n",
    "ArbitraryCapitalLetter = np.random.choice(AvailableCapitalLetters, 1, p=(np.array(AvailableCapitalLettersPVector).astype(np.float64)).flatten())[0]\n",
    "print(\"Arbitrary Capital Letter Selected: \",ArbitraryCapitalLetter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can feed this capital letter into GenerateWords! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Words Array:  ['Unite', 'Uniteof', 'Unitate', 'Unithe', 'Unithed', 'Unitathe', 'Unitheopled', 'Unites', 'Unithes', 'United']\n"
     ]
    }
   ],
   "source": [
    "GeneratedRandomWords = GenerateWords(ArbitraryCapitalLetter,ExampleOneCharacterList,10,ExamplePMatrix)\n",
    "print(\"Random Words Array: \",list(GeneratedRandomWords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Checking random words for if they are *real* words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last, the final stretch for this example is figuring out if our list of generated words actually make real words.  One way to accomplish this is by referencing the Scrabble text file with Scrabble-approved words.  \n",
    "\n",
    "Our first task, then, is to read in our Scrabble file into a single, long string and then pass that string into a counter dictionary; similar to what we did for each character, earlier.  We then create another function, ReadAndAppendFileIntoWordArray, that reads in our Scrabble file, parses it a bit, and makes it into a long string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadAndAppendFileIntoWordArray(_InputFilePath):\n",
    "    \"\"\"Read in a file at filepath, count punctuation as words, and return an array of words.\"\"\" \n",
    "    with open(_InputFilePath, 'r') as byteinput:\n",
    "        file = open(_InputFilePath,mode='r') # file data\n",
    "        filestring = file.read() # save the data as a string\n",
    "        file.close()\n",
    "        _OutputString = filestring.replace(\".\", \" . \") \\\n",
    "               .replace(\",\", \" , \") \\\n",
    "               .replace(\"-\", \" - \") \\\n",
    "               .replace(\";\", \" ; \") \\\n",
    "               .replace(\":\", \" : \").split() # remove excess white spaces\n",
    "    return _OutputString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create another function that converts our long string into a counter dictionary, UniqueWordSetCounter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UniqueWordSetCounter(_InputWordArray):\n",
    "    \"\"\"Count the number of occurences for each word in a a filestring\"\"\" \n",
    "    _Counter = collections.Counter(_InputWordArray)\n",
    "    return _Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our two functions, we can make our Scrabble dictionary counter!  The FullScrabbleFilePath variable is in one of the first cells in this paper; the local path just has to be updated accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary of Scrabble words\n",
    "ScrabbleWords = ReadAndAppendFileIntoWordArray(FullScrabbleFilePath)\n",
    "ScrabbleCounter = UniqueWordSetCounter(ScrabbleWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last step is to make a function, LookupWordsInScrabbleDict, that takes our Scrabble dictionary and our generated words and prints out if our generated words are found in the Scrabble dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LookupWordsInScrabbleDict(ScrabbleDict, WordSet):\n",
    "    \"\"\"Given a dictionary, ScrabbleDict, and a set of words to look for in the dictionary, WordSet, print out each word in WordSet and bold the word if it is found in the dictionary.\"\"\"\n",
    "    print(\"\\033[1mBolded\\033[0m words are in the Scrabble Dictionary\")\n",
    "    WordCount = 0\n",
    "    for word in WordSet:\n",
    "        if(ScrabbleDict.get(word.upper().replace(' ','')) == None):\n",
    "            print(\"{}\".format(word))\n",
    "        else:\n",
    "            print(\"\\033[1m{}\\033[0m\".format(word))\n",
    "            WordCount = WordCount + 1\n",
    "    print(\"\\033[1mReal Word Count: \\033[0m\",WordCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBolded\u001b[0m words are in the Scrabble Dictionary\n",
      "\u001b[1mUnite\u001b[0m\n",
      "Uniteof\n",
      "Unitate\n",
      "Unithe\n",
      "Unithed\n",
      "Unitathe\n",
      "Unitheopled\n",
      "\u001b[1mUnites\u001b[0m\n",
      "Unithes\n",
      "\u001b[1mUnited\u001b[0m\n",
      "\u001b[1mReal Word Count: \u001b[0m 3\n"
     ]
    }
   ],
   "source": [
    "LookupWordsInScrabbleDict(ScrabbleCounter,GeneratedRandomWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome!  We now have a process for creating random words based off of an input dictionary and by using single-character prediction.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving Onto One-Letter Prediction:\n",
    "\n",
    "Now onto the first challenge in this paper, one-letter prediction for the entire Constitution.  Not surprisingly, none of underlying code from our simple example above changes much.  All that changes is our input, the full Constitution of the United States."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to read in the entire Constitution as a string.  We can accomplish this by using the url.request library to read in the const.txt file from our provided url, https://www.usconstitution.net/const.txt, as a bytearray, then converting that byte array into a large string.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadAndAppendConstitutionURLIntoString(url):\n",
    "    \"\"\"Provided a valid URL, url, read in the file located at the url, decode it into a string, parse the string a bit to take out uncessary characters, then return the resulting string.\"\"\"\n",
    "    #Python 3 reads html as a bytearray\n",
    "    file = urllib.request.urlopen(\"https://www.usconstitution.net/const.txt\")\n",
    "    filebytes = file.read()\n",
    "\n",
    "    #Decode bytearray to string (assuming utf8 encoding)\n",
    "    rawfilestring = filebytes.decode(\"utf8\")\n",
    "    file.close()\n",
    "\n",
    "    #print(rawfilestring)\n",
    "    FullConstitutionString = rawfilestring[rawfilestring.index(\"We the People\"):].replace('\\n', ' ').replace('\\r', ' ')\n",
    "    FullConstitutionString = ' '.join(FullConstitutionString.split())\n",
    "    \n",
    "    return FullConstitutionString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileString = ReadAndAppendConstitutionURLIntoString(ConstitutionURL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Find the set of all unique characters used in the Constitution of the United States and call the size of that set $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did in the example, we need to first find all of the unique characters in the Constitution.  We can use the same function for this, UniqueCharacterSetCounter.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Unique Characters:  69\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create a counter dictionary of unique characters in the file\n",
    "OneCharacterCounter = UniqueCharacterSetCounter(FileString,1)\n",
    "\n",
    "#Number of unique characters\n",
    "n = len(OneCharacterCounter) \n",
    "print(\"Total Number of Unique Characters: \",n)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create a transition probability matrix, $P$, with shape $n \\times n$ that contains the probabilities where $P_{i,j}$ represents the probability that the next character is $j$, given the current character is $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know the total number of unique characters, and their occurrences, in our OneCharacterCounter counter dictionary, we can start to build our transition probability matrix.\n",
    "\n",
    "We begin by counting and figuring out the unique character-pairs in our input string, the Constitution, and make a TwoCharactersCounter counter dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a counter dictionary of character pairs to help create our transition probability matrix\n",
    "TwoCharactersCounter = UniqueCharacterSetCounter(FileString,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to keep everything constitent from run-to-run, we also sort the OneCharacterList by most common to least common characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a sorted character list based off of the OneCharacterCounter counter dictionary\n",
    "OneCharacterList = OneCharacterCounter.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have everything to plug into our Create2DPMatrix function in order to create our transitional probability matrix, which we can then verify using VerifyValid2DPMatrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneCharacterPMatrix = Create2DPMatrix(OneCharacterList,OneCharacterCounter,TwoCharactersCounter,FileString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VerifyValid2DPMatrix(OneCharacterPMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Simulate the Markov process by starting with an arbitary capital letter from our dictionary.  Make 100 random *words* and see how many are actually words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have our transition probability matrix, we can now move onto making random words.  We can use the same method as before, which was to select a random first capital letter from our OneCharacterList by creating its transition probability vector and np.random.choice.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arbitrary Capital Letter Selected:  T\n"
     ]
    }
   ],
   "source": [
    "#Selecting an arbitrary first capital letter\n",
    "AvailableCapitalLetters, AvailableCapitalLettersPVector = CreateCharacterPVector(OneCharacterList, _CapitalLettersOnly=True)\n",
    "ArbitraryCapitalLetter = np.random.choice(AvailableCapitalLetters, 1, p=(np.array(AvailableCapitalLettersPVector).astype(np.float64)).flatten())[0]\n",
    "print(\"Arbitrary Capital Letter Selected: \",ArbitraryCapitalLetter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily our GenerateWords function still works for this situation, as well, so all we need to do is plug in our updated ArbitraryCapitalLetter, OneCharacterList, desired number of random words, and OneCharacterPMatrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "GeneratedRandomWords = GenerateWords(ArbitraryCapitalLetter,OneCharacterList,100,OneCharacterPMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the same method as before for looking up these new random words in the Scrabble dictionary, too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBolded\u001b[0m words are in the Scrabble Dictionary\n",
      "Thace\n",
      "Thevenan\n",
      "Tericetero\n",
      "Trthait\n",
      "Thericthe\n",
      "Thidmect\n",
      "Trtio\n",
      "Tenceror\n",
      "Toua\n",
      "Thelon\n",
      "Thentesh\n",
      "Thevenigion\n",
      "Thalicendsh\n",
      "\u001b[1mTor\u001b[0m\n",
      "Tourechely\n",
      "Thinden\n",
      "Thapr\n",
      "Thal\n",
      "Touprichas\n",
      "Thenerist\n",
      "Trereiaxte\n",
      "\u001b[1mTry\u001b[0m\n",
      "Tof\n",
      "Theilisutor\n",
      "Thasunetty\n",
      "Theren\n",
      "Thame\n",
      "Thenovorrme\n",
      "Tred\n",
      "Thovecopawiore\n",
      "Tontre\n",
      "Thesof\n",
      "\u001b[1mThe\u001b[0m\n",
      "Torcr\n",
      "Thre\n",
      "Tiory\n",
      "Thtache\n",
      "Thallofinda\n",
      "Trernduchereimall\n",
      "\u001b[1mTire\u001b[0m\n",
      "Trofoff\n",
      "Thompredeale\n",
      "Tateris\n",
      "\u001b[1mTe\u001b[0m\n",
      "Tibostiomomes\n",
      "Thay\n",
      "\u001b[1mTo\u001b[0m\n",
      "Thelepus\n",
      "Thigall\n",
      "Thume\n",
      "\u001b[1mTot\u001b[0m\n",
      "Thate\n",
      "Trangalisin\n",
      "Thefome\n",
      "Trng\n",
      "Trentes\n",
      "Ther\n",
      "Tre\n",
      "Tren\n",
      "Thallll\n",
      "Tidexevoumongir\n",
      "\u001b[1mToo\u001b[0m\n",
      "Tipur\n",
      "\u001b[1mThale\u001b[0m\n",
      "Thed\n",
      "Tononicteiathery\n",
      "Tidssorof\n",
      "Trmenthoritaprrtes\n",
      "Theputhappullliolichapes\n",
      "Thand\n",
      "\u001b[1mTore\u001b[0m\n",
      "Toredende\n",
      "Thatecllideve\n",
      "Theshfucthawh\n",
      "Trte\n",
      "Tr\n",
      "Thes\n",
      "Thacofrig\n",
      "Thashe\n",
      "Theng\n",
      "Thanus\n",
      "Thecesilo\n",
      "Trser\n",
      "Tobe\n",
      "Tanmmbes\n",
      "\u001b[1mThaw\u001b[0m\n",
      "\u001b[1mTorous\u001b[0m\n",
      "Thashateed\n",
      "Thesicenvan\n",
      "Troor\n",
      "Toin\n",
      "\u001b[1mTrem\u001b[0m\n",
      "Thecathere\n",
      "Talleatide\n",
      "Tollallll\n",
      "Thereexcon\n",
      "Tol\n",
      "Ticot\n",
      "Tw\n",
      "Th\n",
      "\u001b[1mReal Word Count: \u001b[0m 13\n"
     ]
    }
   ],
   "source": [
    "#Create a dictionary of Scrabble words\n",
    "ScrabbleWords = ReadAndAppendFileIntoWordArray(FullScrabbleFilePath)\n",
    "ScrabbleCounter = UniqueWordSetCounter(ScrabbleWords)\n",
    "\n",
    "LookupWordsInScrabbleDict(ScrabbleCounter,GeneratedRandomWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving Onto Two-Letter Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can move onto our Two-Letter prediction problem in this paper.  This problem is different in that while it still follows the Markov property, the next state is dependent on the current state *and* the previous state.  To review again, we can describe this behavior the following way:\n",
    "$$\n",
    "P[X_{n+1} = k \\;|\\; X_n = j,X_{n-1} = i, X_{n-2} = i_{n-2}, ..., X_0 = i_0 ] = P[X_{n+1} = k \\;|\\; X_n = j,X_{n-1} = i] = P_{i,j,k},\n",
    "$$\n",
    "where X is a random variable representing an ascii character."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Find the set of all unique characters used in the Constitution of the United States and call the size of that set $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using the same dictionary, we can use the same n as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique characters:  69\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create a counter dictionary of unique characters in the file\n",
    "OneCharacterCounter = UniqueCharacterSetCounter(FileString,1)\n",
    "\n",
    "#Number of unique characters\n",
    "n = len(OneCharacterCounter) \n",
    "print(\"Total number of unique characters: \",n)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create a transition probability matrix, $P$, with shape $n \\times n \\times n$ that contains the probabilities where $P_{i,j,k}$ represents the probability that the next character is $k$, given the current character is $j$ and the previous character was i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are now working with a $n \\times n \\times n$ matrix, we need to modify our Create2DPMatrix function a bit to make it Create3DPMatrix.  This simply involves adding another index for loop inside our existing row and column for loops.  This way, we can iterate through every element, $P_{i,j,k}$, in the transition probability matrix, $P$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create3DPMatrix(_OneCharacterList,_TwoCharactersCounter,_ThreeCharactersCounter,_FileString):\n",
    "    \"\"\"Given a character list, _OneCharacterList, two counters, _TwoCharactersCounter and _ThreeCharactersCounter, and a long file string, _FileString, return a transition probability matrix.\"\"\"\n",
    "    n = len(_OneCharacterList)\n",
    "    _P = np.zeros((n,n,n))\n",
    "\n",
    "    #Pair the last two characters with the most common character to complete the pair and make the probability of the last character pair equal to 1\n",
    "    LastTwoCharactersOfFile = LastCharacterOfFileString(_FileString,2)\n",
    "    _P[CharacterIndexSearch(_OneCharacterList,LastTwoCharactersOfFile[0]),CharacterIndexSearch(_OneCharacterList,LastTwoCharactersOfFile[1]),CharacterIndexSearch(_OneCharacterList,' ')] = 1/_TwoCharactersCounter.get(LastTwoCharactersOfFile)\n",
    "\n",
    "    for row in range(np.shape(_P)[0]):\n",
    "        for col in range(np.shape(_P)[1]):\n",
    "            for index in range(np.shape(_P)[1]):\n",
    "                if(ThreeCharactersCounter.get(_OneCharacterList[row][0] + _OneCharacterList[col][0] + _OneCharacterList[index][0]) != None):\n",
    "                    _P[row,col,index] += _ThreeCharactersCounter.get(_OneCharacterList[row][0] + _OneCharacterList[col][0] + _OneCharacterList[index][0])/_TwoCharactersCounter.get(_OneCharacterList[row][0] + _OneCharacterList[col][0])\n",
    "    return _P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another addition we have to incorportate is a ThreeCharactersCounter, which helps us map and count our first two unique character-pairs to a third character found in our dictionary.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "TwoCharactersCounter = UniqueCharacterSetCounter(FileString,2)\n",
    "ThreeCharactersCounter = UniqueCharacterSetCounter(FileString,3)\n",
    "\n",
    "#Make all of our counter dictionaries into sorted lists, from most common to least common unique combinations\n",
    "OneCharacterList = OneCharacterCounter.most_common()\n",
    "TwoCharactersList = TwoCharactersCounter.most_common()\n",
    "ThreeCharactersList = ThreeCharactersCounter.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final change we have to incorporate is our transition probability matrix verification, since we added another dimension to our matrix, we need to make appropriate changes to our function.  As mentioned early on in the paper, our transition probability matrix this time around will have some additional rows that only sum to 0.  This is because we are first creating the $P$ matrix based off all the unique characters, $n$, which can create character-pairs, $n \\times n$, that might not exist in our dictionary.  So we change our VerifyValid3DPMatrix function to simply ignore this case.  Now we are only failing rows that do not sum perfectly to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VerifyValid3DPMatrix(Pmatrix):\n",
    "    \"\"\"Given a transition probability matrix, Pmatrix, verify each row in the matrix sums to 1.\"\"\"\n",
    "    TrackingBool = True\n",
    "    for row in np.arange(Pmatrix.shape[0]):\n",
    "        for col in np.arange(Pmatrix.shape[1]):\n",
    "            if((np.round(np.sum(Pmatrix[row,col,:]),10)) == 0):\n",
    "                continue\n",
    "            if( (np.round(np.sum(Pmatrix[row,col,:]),10)) != 1):\n",
    "                print(\"Sum of row,{}, col, {}, does not equal 1!\".format(row,col))\n",
    "                print(Pmatrix[row,col,:])\n",
    "                TrackingBool = False\n",
    "    return TrackingBool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ThreeCharacterPMatrix = Create3DPMatrix(OneCharacterList,TwoCharactersCounter,ThreeCharactersCounter,FileString)\n",
    "VerifyValid3DPMatrix(ThreeCharacterPMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Simulate the Markov process by starting with an arbitary capital letter from our dictionary.  Make 100 random *words* and see how many are actually words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to simulate our Markov process this time, we need to select the first *two* letters to begin our process.  Fortunately, we can use the same CreateCharacterPVector to make a transition probability vector of all of the character-pairs that contain capital letters.  We can then use the same np.random.choice method for choosing one of these character-pairs based off of their probability vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arbitrary Capital Letter-Pair Selected:   C\n"
     ]
    }
   ],
   "source": [
    "#Selecting an arbitrary first capital letter\n",
    "AvailableCapitalLetters, AvailableCapitalLettersPVector = CreateCharacterPVector(TwoCharactersList, _CapitalLettersOnly=True)\n",
    "ArbitraryCapitalLetterPair = np.random.choice(AvailableCapitalLetters, 1, p=(np.array(AvailableCapitalLettersPVector).astype(np.float64)).flatten())[0]\n",
    "print(\"Arbitrary Capital Letter-Pair Selected: \",ArbitraryCapitalLetterPair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are now creating random words based off of two characters, we have to update our GenerateWords function to GenerateWordsTwoLetter.  Our new function just has to be able to track probability vectors based off of the currently indexed character and the previously indexed character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateWordsTwoLetter(FirstTwoLetters,OneCharacterList,Pmatrix,NumberOfWords):\n",
    "    \"\"\"Given two first letters, FirstTwoLetters, a list of characters, OneCharacterList, the number of words to create, NumberOfWords, and a transition probability matrix, Pmatrix,\"\"\"\n",
    "    \"\"\"return _NumberOfWords random words, WordSet.\"\"\"\n",
    "    CharacterListLetters = [index[0] for index in OneCharacterList]\n",
    "    LoopLimit = 0\n",
    "    WordArray = []\n",
    "    WordSet = {}\n",
    "    #Generate unique words until looplimit\n",
    "    while ( (len(WordSet) != NumberOfWords) and (LoopLimit < 1000) ):\n",
    "        CurrentCharacter = FirstTwoLetters[1]\n",
    "        CurrentFirstCharacterIndex = CharacterIndexSearch(OneCharacterList, FirstTwoLetters[0])\n",
    "        CurrentSecondCharacterIndex = CharacterIndexSearch(OneCharacterList, FirstTwoLetters[1])\n",
    "        Word = FirstTwoLetters\n",
    "        while (CurrentCharacter != \" \"): \n",
    "            CurrentCharacter = list(np.random.choice(CharacterListLetters, 1, p=(np.array(Pmatrix[CurrentFirstCharacterIndex,CurrentSecondCharacterIndex,:]).astype(np.float64)).flatten()))[0]\n",
    "            CurrentFirstCharacterIndex = CurrentSecondCharacterIndex\n",
    "            CurrentSecondCharacterIndex = CharacterIndexSearch(OneCharacterList, CurrentCharacter)\n",
    "            Word = Word + CurrentCharacter\n",
    "        #Condition the word so that it can be a *real* word without punctuation\n",
    "        Word = (Word.translate(str.maketrans('', '', string.punctuation))).replace(' ','')\n",
    "        WordArray.append(Word)\n",
    "        WordSet = set(WordArray)\n",
    "        LoopLimit = LoopLimit + 1\n",
    "    return WordSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Letter:   C\n",
      "\u001b[1mBolded\u001b[0m words are in the Scrabble Dictionary\n",
      "Conmentat\n",
      "Cas\n",
      "Cary\n",
      "\u001b[1mClan\u001b[0m\n",
      "Choody\n",
      "Carthe\n",
      "Coneclaction\n",
      "Convilithe\n",
      "\u001b[1mCits\u001b[0m\n",
      "\u001b[1mCons\u001b[0m\n",
      "Conatinfectined\n",
      "Chold\n",
      "Constationerate\n",
      "Congreizenater\n",
      "\u001b[1mClays\u001b[0m\n",
      "Conspell\n",
      "Coneedution\n",
      "Capprovidennes\n",
      "Consuchooside\n",
      "Cesident\n",
      "Couse\n",
      "Casucholecuthe\n",
      "\u001b[1mCited\u001b[0m\n",
      "Councity\n",
      "\u001b[1mCase\u001b[0m\n",
      "Const\n",
      "Consted\n",
      "Conspers\n",
      "Courislareens\n",
      "Cappoing\n",
      "Consentrumearand\n",
      "Com\n",
      "\u001b[1mCars\u001b[0m\n",
      "Consen\n",
      "Conste\n",
      "Citle\n",
      "\u001b[1mConey\u001b[0m\n",
      "Carlegis\n",
      "Citesidensed\n",
      "Cass\n",
      "Cason\n",
      "\u001b[1mCor\u001b[0m\n",
      "\u001b[1mCot\u001b[0m\n",
      "Cont\n",
      "Cassurposend\n",
      "Congre\n",
      "Conse\n",
      "Cith\n",
      "\u001b[1mClass\u001b[0m\n",
      "Crithoundenforess\n",
      "Conmee\n",
      "\u001b[1mConto\u001b[0m\n",
      "Congaint\n",
      "\u001b[1mCone\u001b[0m\n",
      "\u001b[1mCite\u001b[0m\n",
      "Cong\n",
      "Commited\n",
      "\u001b[1mCart\u001b[0m\n",
      "Citned\n",
      "Cout\n",
      "Confecom\n",
      "Consylacies\n",
      "\u001b[1mCon\u001b[0m\n",
      "Constionst\n",
      "Conitte\n",
      "Casideby\n",
      "Conckned\n",
      "Casom\n",
      "Constivalis\n",
      "Cartion\n",
      "Carly\n",
      "Cresident\n",
      "Caratimented\n",
      "\u001b[1mCases\u001b[0m\n",
      "Clars\n",
      "\u001b[1mConstates\u001b[0m\n",
      "Carged\n",
      "Crition\n",
      "Crithe\n",
      "\u001b[1mCond\u001b[0m\n",
      "\u001b[1mCites\u001b[0m\n",
      "Consappromeentany\n",
      "Cought\n",
      "Citne\n",
      "\u001b[1mChime\u001b[0m\n",
      "Casent\n",
      "Cousention\n",
      "\u001b[1mCouth\u001b[0m\n",
      "Critembe\n",
      "Casuragary\n",
      "Considentates\n",
      "Congs\n",
      "Claidem\n",
      "Coing\n",
      "Coutiong\n",
      "Consese\n",
      "Consuch\n",
      "Cousedfur\n",
      "\u001b[1mClaw\u001b[0m\n",
      "Conseld\n",
      "\u001b[1mReal Word Count: \u001b[0m 23\n"
     ]
    }
   ],
   "source": [
    "RandomWords = GenerateWordsTwoLetter(ArbitraryCapitalLetterPair,OneCharacterList,ThreeCharacterPMatrix,100)\n",
    "print(\"Random Letter: \",ArbitraryCapitalLetterPair)\n",
    "#print(\"Random Letter Array: \",RandomWords)\n",
    "LookupWordsInScrabbleDict(ScrabbleCounter,RandomWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Let Us Try One-Word Prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can currently create random words from one-letter and two-letter prediction.  But how difficult is it to create random *sentences* from one-word prediction?  Surprisingly, or perhaps not surprisingly, it is not too different from one-letter prediction; we are only switching a character for a word.\n",
    "\n",
    "That does not mean we can just plug in words instead of one or two characters into our functions, however.  We will have to make some minor changes.\n",
    "\n",
    "The first change is how we are interpreting the Constitution.  In order to break the Constitution up into words, we will split words, including punctuation, by using white-space as a delimeter.  Therefore, we intentionally add white space around existing punctuation and then invoke the split() function, which splits the Constitution variable, FileString, up into an array of strings that are words, FileWordArray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileWordArray = (FileString.replace(\",\", \" , \").replace(\".\", \" . \").replace(\"-\", \" - \").replace(\";\", \" ; \").replace(\":\", \" : \")).split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a word array, we can use the same function we used for making a counter dictionary of words for the Scrabble dictionary, UniqueWordSetCounter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Find the set of all unique words used in the Constitution of the United States and call the size of that set $m$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we can use the existing UniqueWordSetCounter function, we can easily get the unique words and their respective counts easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Unique Words:  1352\n",
      "\n"
     ]
    }
   ],
   "source": [
    "OneWordCounter = UniqueWordSetCounter(FileWordArray)\n",
    "\n",
    "#Number of unique words\n",
    "m = len(OneWordCounter) \n",
    "print(\"Total Number of Unique Words: \",m)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create a transition probability matrix, $P$, with shape $m \\times m$ that contains the probabilities where $P_{i,j}$ represents the probability that the next word is $j$, given the current word is $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make a two-word counter dicitonary, we have to tweak UniqueWordSetCounter a bit, below; we can iterate through the entire input FileWordArray to create overlapping pairs of words.  We will need this in the future for when we are creating our transition probability matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UniqueTwoWordSetCounter(_WordArray):\n",
    "    \"\"\"Count the number of occurences for each word in a file located at filepath\"\"\" \n",
    "    _WordPairs = collections.Counter([_WordArray[i] + \" \" + _WordArray[i+1] for i in range(0,len(_WordArray)-1,1)])\n",
    "    return _WordPairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a counter dictionary of word pairs to help create our transition probability matrix\n",
    "TwoWordsCounter = UniqueTwoWordSetCounter(FileWordArray)\n",
    "\n",
    "OneWordList = list(OneWordCounter.most_common())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now *almost* have everything to create our transitional probability matrix, which we can then verify using a verify P matrix function.  We just need to make slight modifications to our existing probability matrix and verification functions in order to make them work with words and adjust our helper functions accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first small change is just renaming our LastCharacterOfFileString function to LastWordOfWordArray.  This is just to make it easier to read what our Create2DWordPMatrix is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LastWordOfWordArray(_WordArray):\n",
    "    \"\"\"Return the last word of the input _WordArray\"\"\"\n",
    "    return _WordArray[-1:][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next change is to our CharacterIndexSearch to WordIndexSearch.  Again, this is just a renaming for clarity's sake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WordIndexSearch(WordList,WordSearch):\n",
    "    \"\"\"Given a WordList and a WordSearch word to search for in the WordList.\"\"\"\n",
    "    \"\"\"Return either the index for the found word in the WordList or return -1 if the WordSearch could not be found.\"\"\"\n",
    "    counter = 0\n",
    "    for index in WordList:\n",
    "        WordSearchIndex = -1\n",
    "        if index[0] == WordSearch:\n",
    "            WordSearchIndex = counter\n",
    "            break\n",
    "        counter = counter + 1\n",
    "    return WordSearchIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, getting to our Create2DWordPMatrix function, we mainly change our CharacterList and CharacterCounters to WordLists and WordCounters.  We also handle the last word in the FileWordArray so that it is not ignored and instead is reconnected to 'the'.  This is just to make the probability of the row for the last character to equal 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create2DWordPMatrix(_OneWordList,_OneWordCounter,_TwoWordsCounter,_InputWordArray):\n",
    "    \"\"\"Given a WordList, _OneWordList, of single unique words, and two counters of unique single-words and unique word-pairs, _OneWordCounter and _TwoWordsCounter,\"\"\"\n",
    "    \"\"\"return a transition probability matrix, _P.\"\"\"\n",
    "    n = len(_OneWordList)\n",
    "    _P = np.zeros((n,n))\n",
    "    _P[WordIndexSearch(_OneWordList,LastWordOfWordArray(_InputWordArray)),WordIndexSearch(_OneWordList, 'the')] = 1/_OneWordCounter.get(LastWordOfWordArray(_InputWordArray))\n",
    "    for row in range(np.shape(_P)[0]):\n",
    "        for col in range(np.shape(_P)[1]):\n",
    "            if(_TwoWordsCounter.get(_OneWordList[row][0] + \" \" + _OneWordList[col][0]) != None):\n",
    "                _P[row,col] += _TwoWordsCounter.get(_OneWordList[row][0] + \" \" + _OneWordList[col][0])/_OneWordList[row][1]\n",
    "    return _P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OneWordPMatrix = Create2DWordPMatrix(OneWordList,OneWordCounter,TwoWordsCounter,FileWordArray)\n",
    "\n",
    "VerifyValid2DPMatrix(OneWordPMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Simulate the Markov process by starting with an arbitary capital word from our dictionary.  Make ~10 random *sentences*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as when we were simulating the Markov process for one-character prediction, we utilize a function like CreateCharacterPVector, renamed to CreateWordPVector.  The notable changes are the handlnig for words instead of characters and also the check for Capital *words* by using the .istitle() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateWordPVector(_WordList,_LettersOnly=True,_CapitalLettersOnly=True):\n",
    "    \"\"\"Given a _WordList, return a list of wrods and a transition probability vector, Pvector, for those capital letters\"\"\"\n",
    "    _Words = []\n",
    "    OccurenceSum = 0\n",
    "    _PVector = []\n",
    "    \n",
    "    for index in _WordList:\n",
    "        if(_CapitalLettersOnly):\n",
    "            if(index[0].istitle()):\n",
    "                _Words.append(index[0])\n",
    "                OccurenceSum += index[1]\n",
    "                _PVector.append(index[1])\n",
    "        elif(_LettersOnly):\n",
    "            if(index[0].isalpha()):\n",
    "                _Words.append(index[0])\n",
    "                OccurenceSum += index[1]\n",
    "                _PVector.append(index[1])\n",
    "        else:\n",
    "            _Words.append(index[0])\n",
    "            OccurenceSum += index[1]\n",
    "            _PVector.append(index[1])\n",
    "    for index in range(len(_Words)):\n",
    "        _PVector[index] = _PVector[index]/OccurenceSum\n",
    "    return _Words, _PVector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can get our available first words to choose from and their respective probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "AvailableCapitalWords, AvailableCapitalWordsPVector = CreateWordPVector(OneWordList,_CapitalLettersOnly=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first major divergence from our one-character prediction setup happens here.  Before, we simply selected a single arbitrary capital letter and then generated words with the same capital letter.  However, since we have fewer capitalized words and especially more capitalized words that only have one tranition to the '.' *word*, which ends our sentences, we need to select more arbitary first words.\n",
    "\n",
    "Therefore, we can use the below while loop to iterate through the probability vector, AvailableCapitalWordsPVector, until we have 100 ArbitraryWords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ArbitraryWords = []\n",
    "while(len(ArbitraryWords) != 100):\n",
    "    NewRandomWord = np.random.choice(AvailableCapitalWords, 1, p=(np.array(AvailableCapitalWordsPVector).astype(np.float64)).flatten())[0]\n",
    "    try:\n",
    "        ArbitraryWords.index(NewRandomWord)\n",
    "    except:\n",
    "        ArbitraryWords.append(NewRandomWord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now feed these ArbitraryWords into an updated GenerateWord function, GenerateSentences.  GenerateSentences is different in that it accepts an array of \\_FirstWords and each iteration of the while loop selects the next word available in the \\_FirstWords.  It also conditions the output sentences so that punctuation is visually correct.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateSentences(_FirstWords,_WordList,_NumberOfSentences,_Pmatrix):\n",
    "    \"\"\"Given a list of words, _FirstWords, a list of words, _WordList, the number of words to create, _NumberOfSentences, and a transition probability matrix, _Pmatrix,\"\"\"\n",
    "    \"\"\"return _NumberOfWords random words, _SentenceSet.\"\"\"\n",
    "    WordListWords = [index[0] for index in _WordList]\n",
    "    LoopLimit = 0\n",
    "    SentenceArray = []\n",
    "    _SentenceSet = {}\n",
    "    #generate unique words until looplimit\n",
    "    while ( (_NumberOfSentences != len(_SentenceSet)) and (LoopLimit < 1000) and (LoopLimit < len(_FirstWords))):\n",
    "        CurrentWord = _FirstWords[LoopLimit]\n",
    "        CurrentWordIndex = WordIndexSearch(_WordList, _FirstWords[LoopLimit])\n",
    "        Sentence = CurrentWord\n",
    "        while (CurrentWord != \".\"): \n",
    "            CurrentWord = list(np.random.choice(WordListWords, 1, p=(np.array(_Pmatrix[CurrentWordIndex,:]).astype(np.float64)).flatten()))[0]\n",
    "            CurrentWordIndex = WordIndexSearch(_WordList, CurrentWord)\n",
    "            Sentence = Sentence + \" \" + CurrentWord\n",
    "        #Condition the word so that it can be a *real* word without punctuation\n",
    "        SentenceArray.append(Sentence.replace(\" , \",\", \").replace(\" . \",\".\").replace(\" .\",\".\").replace(\" - \",\"-\").replace(\" ; \",\"; \").replace(\" : \",\": \"))\n",
    "        _SentenceSet = set(SentenceArray)\n",
    "        LoopLimit = LoopLimit + 1\n",
    "    return _SentenceSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can plug our necessary inputs into GenerateSentences to make 10 ramdom sentences!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Sentence:  United States, shall be quartered in Cases, both Houses that purpose shall act accordingly, open Court, and other State on the legislature, and Felonies committed on the office or other Property belonging to ourselves and a member of the United States, Charles Cotesworth Pinckney, and naval forces, or naturalized in a quorum for the Laws of the several States; To declare the President, the Government, and eight, Thomas Fitzsimons, the fourth day. \n",
      "Random Sentence:  Rhode Island and enjoy any State. \n",
      "Random Sentence:  To provide for the United States; a Resident within, or possession of honor, giving them, when elected, and he shall take Care that State in December, or when the first Meeting shall then the several State, and for the land or members from the United States, to the list, one, without the Appointment of the government of the Receipts and Fact, both Houses shall flee from Office on Imports or other Officers; to enter, Imposts and all other Mode of Adjournment) shall be elected, be taken by any primary or abridged, shall have power to make all such Regulations, and recommend to the United States to the Progress of Adjournment) shall have been ratified as President, other tax or ex post facto Law make any State; otherwise, and Reprisal, and claims shall be so ratifying the Vice President, Gunning Bedford Jr. \n",
      "Random Sentence:  States, shall not admit of twenty one of President, be formed or Representative; To define and if there should remain two years; which the United States, declaring who shall be absolutely necessary to any State with his office of the twelfth article shall issue, in the next Meeting of the Congress shall sign and returning from each; nor any Speech or equity, and the Opinion, or ex post facto Law and by law provide for the nature and if it to any Speech or Exports, in the Congress shall become President, Pennsylvania eight shall have one Representative shall, That the Rules and Representatives his death or more who shall not in levying War in choosing the supreme Court; To make temporary Appointments are eighteen years from, directed. \n",
      "Random Sentence:  Coin of a Citizen, the office of such Service for six Years after the whole Number of age. \n",
      "Random Sentence:  Names of them, Charles Pinckney, or other Crime, and the two persons having the several States; and Representatives. \n",
      "Random Sentence:  No person except in the United States. \n",
      "Random Sentence:  State to Indictment, in the greatest Number of any State. \n",
      "Random Sentence:  Representation from two persons voted for President, which he may direct Taxes, by the Legislatures of the Vice President, or more States, or of the high Crimes and in the Territory, be questioned in the District would be a different day to lay and all other public Safety may choose by Oath or military, by Law. \n",
      "Random Sentence:  Speech or Subjects. \n"
     ]
    }
   ],
   "source": [
    "RandomSentences = GenerateSentences(ArbitraryWords,OneWordList,10,OneWordPMatrix)\n",
    "X = [print(\"Random Sentence: \",RandomSentence,\"\") for RandomSentence in RandomSentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "HW_10_Due_12_15.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
